{"meta":{"title":"施长成的博客","subtitle":"博客","description":"施长成的博客","author":"shicc","url":"http://blog.shicc.top"},"pages":[{"title":"About","date":"2017-11-25T05:06:55.000Z","updated":"2018-12-03T10:19:55.678Z","comments":true,"path":"about/index.html","permalink":"http://blog.shicc.top/about/index.html","excerpt":"","text":"现状 工作中 技能语言类 java 熟练 前端相关 熟练 大数据 学习 python 入门 工具类 git 熟练 docker 初步 shell/bash/zsh 初步 Jmeter 熟练"},{"title":"tags","date":"2017-11-25T05:04:33.000Z","updated":"2018-12-03T10:19:55.679Z","comments":true,"path":"tags/index.html","permalink":"http://blog.shicc.top/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-05-12T13:31:20.000Z","updated":"2018-12-03T10:19:55.679Z","comments":false,"path":"categories/index.html","permalink":"http://blog.shicc.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Java Transient","slug":"Java Transient ","date":"2019-03-07T10:58:42.000Z","updated":"2019-03-07T11:08:03.917Z","comments":true,"path":"Java Transient .html","link":"","permalink":"http://blog.shicc.top/Java Transient .html","excerpt":"","text":"序列化我们的Java对象并不只是存在内存中，优势还需要在网络中传输，或保存到硬盘中再下次需要时再加载出来，所有我们需要使用到Java序列化技术。 Java 序列化正是讲对象变成一串由二进制字符组成的数组，可以通过将二进制数据保存到磁盘或者传输网络，磁盘或者网络接收者可以在对象的属类的模版上来反序列化类的对象，以达到对象持久化的目的。 Java 对象序列化方式在Java中有两种序列化的方式,Serializable 和 Externalizable,可能大部分人值知道Serializable而不知道Externalizable. 这两种序列化方式的区别是：实现了Serializable接口是自动序列化的，实现Externalizable则需要手动序列化，通过 writeExternal 和readExternal 方式手动进行。 transient 关键字总结 transient修饰的变量不能被序列化。 transient只作用域实现Serializable接口 transient只能用来修饰普通成员变量字段 不管有没有transient修饰，静态变量都不能序列化","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.shicc.top/tags/Java/"},{"name":"Transient","slug":"Transient","permalink":"http://blog.shicc.top/tags/Transient/"},{"name":"序列化","slug":"序列化","permalink":"http://blog.shicc.top/tags/序列化/"}]},{"title":"Redis集群搭建","slug":"Redis集群搭建","date":"2019-01-17T14:01:16.000Z","updated":"2019-01-17T14:09:11.480Z","comments":true,"path":"Redis集群搭建.html","link":"","permalink":"http://blog.shicc.top/Redis集群搭建.html","excerpt":"","text":"Redis 集群搭建 Redis 关闭 1redis-cli -h ip -p port -a pwd shutdown 取消所有Redis的密码设置 配置 dir ，若不配置dir，Redis启动时会根据当前执行目录生成相关数据和配置信息，不方便管理 启动所有的Redis实例 1redis-server /midware/redis/cluster/7000/redis.conf &amp; 查询Redis集群状态 123CLUSTER INFOCLUSTER NODE 构建集群 1./redis/bin/redis-trib.rb create --replicas 1 10.10.118.37:7000 10.10.118.37:7001 10.10.118.38:7000 10.10.118.38:7001 10.10.118.39:7000 10.10.118.39:7001 再次查询Redis集群状态 关闭所有Redis，重新设置密码，再启动","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.shicc.top/tags/Redis/"},{"name":"集群","slug":"集群","permalink":"http://blog.shicc.top/tags/集群/"}]},{"title":"Liunx学习笔记","slug":"Liunx学习笔记","date":"2019-01-17T05:29:00.000Z","updated":"2019-01-18T08:30:15.218Z","comments":true,"path":"Liunx学习笔记.html","link":"","permalink":"http://blog.shicc.top/Liunx学习笔记.html","excerpt":"","text":"Liunx 学习笔记Liunx 目录介绍根目录/bin : 包含二进制文件，即可执行程序，这些程序是系统必需的文件/sbin : 也用于存储二进制文件，只有超级用户root才可以使用/etc : 存放配置文件，如passwd,inittab等/boot : 系统引导时使用的文件，系统中非常重要的内核 vmlinux 就放在该目录下面/dev : 存放设备文件，用户可以通过这些文件访问外部设备/lib : 存放程序运行时所需要的库文件/temp : 存放各种临时文件/mnt : 安装软盘，光盘，U盘的挂载点/root : 超级用户的个人主目录/usr : 该目录的空间比较大，用于安装各种应用程序/proc : 是一个虚拟目录，存放当前内存的印象，有内核自动产生/var : 存放一些会随时改变的文件 常用命令 挂载 Mount /dev/fd0 /mnt/floppy 卸载挂载 Umount /mnt/floppy 启动加载1/etc/fstab ##","categories":[],"tags":[]},{"title":"Spring Boot 教程","slug":"Spring Boot 教程","date":"2018-12-15T10:22:05.000Z","updated":"2019-01-17T14:08:52.238Z","comments":true,"path":"Spring Boot 教程.html","link":"","permalink":"http://blog.shicc.top/Spring Boot 教程.html","excerpt":"","text":"Spring BootApplication事件和监听器除了常见的Spring 框架事件，比如ContextRefreshedEvent，SpringApplication 也会发送其他的application事件。 有些事件实际是在ApplicationContext 创建前触发的，所以你不能在这些事件(处理类)中通过@Bean注册监听器，只能通过SpringApplication.addListeners(...) 或者 SpringApplicationBuilder.listeners(...) 方法注册。 如果想让监听器自动注册，而不关心应用的创建方法，你可以在工程中添加一个META-INF/spring.factories 文件，并使用org.springframework.context.ApplicationListener 作为key 指向那些监听器，如下:1org.springframework.context.ApplicationListener = com.example.project.MyListener 应用运行时，事件会以下面的次序发送： 在运行开始，但除了监听器注册或初始化以外的任务处理之前，会发送一个ApplicationStartedEvent. 在Environment将被用于已知的上下文，但在上下文被创建前，会发送一个ApplicationEnvironmentPreparedEvent 在refresh开始前，但在bean定义已被加载后，会发送一个ApplicationPreparedEvent。 在refresh之后，相关的回调处理完成，会发送一个ApplicationReadyEvent表示应用准备好接受请求了。 启动过程如果出现异常，会发送一个ApplicationFailedEvent。 spring.factories(学习整理一下)官方start格式：spring-boot-start-xxx个人start格式：xxx-spring-boot-start 编写自定义的spring-boot-start 需要借助与 spring.factories,具体的 start 编写方式下方有说明。 java:comp (学习整理一下)@ConfigurationPropertiesRelaxed绑定Spring Boot 将Environment 属性绑定到@ConfigurationProperties beans 时会使用一些宽松的规格，所以Environment属性名和bean属性名不需要精确匹配。常见的示例中有用的包括虚线分割(比如：context-type 绑定到 contextPath)，将environment属性转为大写字母(比如， PORT 绑定到 port) 12345678910@ConfigurationProperties(prefix=&quot;person&quot;)public class OwnerProperties &#123; private String firstName; public String getFirstName() &#123; return this.firstName; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125;&#125; 下面的属性名都能使用： 属性 说明 person.firstName 标准驼峰规则 person.first-name 虚线表示，推荐用于 .properties 和 .yml文件中 person.first_name 下划线表示，用于 .properties 和 .yml 文件的可选格式 PERSON_FIRST_NAME 大写形式，使用系统环境变量时推荐 @ConfigurationProperties VS @Value@Value 是Spring 容器的一个核心特性，它没有提供跟 type-safe Configuration Properties 相同的特性。下面的表格总结了@ConfigurationProperties 和 @Value 支持的特性： 特性 @Configuration @Value Relaxd绑定 Yes NO Meta-data支持 Yes NO SpEL 表达式 NO Yes 如果为自己的组件定义了一些列的keys，那么建议将他们以 @ConfigurationProperties 注解的POJO进行分组。由于 @Value 不支持relaxed绑定，所有如果你使用环境变量属性提供值得话，它就不是很好的选中。最后，尽管 @Value 可以SpEL表达式，但这些表达式不会出来来自Application的属性。 自动配置 auto-configuration从底层讲，自动配置（auto-configurtaion） 是通过标准的@Configuration类实现的。此外，@Conditional 注解用来约束自动配置生效的条件。通常自动配置类需要使用@conditionOnClass 和 @ConditionOnMissingBean 注解，这是为了确保只有在相关的类被发现及没有声明自定义的 @Configuration 时才应用自动配置，具体查看 spring-boot-autofigure源码中的 @Configuration类（META-INF/spring.factories 文件） Spring Boot 会自动检查你发布的jar是否存在 META-INF/spring.factories文件，该文件中以EnableAutoCOnfiguration 为空key的属性应该列出你的配置类1org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.mycirp.libx.autoconfigure.LibXAutoConfiguration,\\com.mycorp.libx.autoconfiguration.LibXWebAutoConfiguration 可以使用 @AutoConfigureAfter或@AutoConfigureBefore注解为配置类指定特定的顺序。例如，你提供了web-specific 配置，你的类就需要应用在WebMvcAutoConfiguration后面。也可以使用 @AutoConfigureOrder 注解为那些相互不知道存在的自动配置类提供排序，该注解语义跟常规的 @Order 注解相同，但专为自动配置提供顺序。 注 自动配置类在只能通过这种方式加载，确保它们定义在一个特殊的package中，特别不能成为组件扫描的目标。 条件注解@ConditionOnMissingBean 注解是一个常见的示例，开发者可以用它覆盖自动配置类提供的默认行为。Spring Boot 包含很多@Conditonal注解，你可以在自己的代码中通过注解@Configuration类或单独的@Bean 方法来重用它们。 Class 条件@ConditionalOnClass 和 @ConditionalOnMissingClass 注解可以根据特定类是否出现来决定配置的包含，由于注解元数据是使用 ASM 来解析的，所以你可以使用 value 属性来引用真正的类，即使该类没有出现在运行的应用的classpath下，也可以使用name属性如果你倾向于使用字符串作为类型。 Bean 条件@ConditionalOnBean 和 @ConditionalOnMissingBean 注解可以根据特定类是否存在决定bean的包含，你可以使用value属性指定beans(by type) ,也可以使用 name 定义beans (by name), search 属性用于限制搜索beans是需要考虑ApplicationContext层次。 注 需要注意bean自定义添加的顺序，因为这些条件的计算是基于目前处理内容的。出于这个原因，我们推荐在自动配置类中只使用 @ConditionOnBean 和 @ConditionOnMissingBean 注解（即使保证他们在其他用户定义的beans后面加载） 注 @ConditionalOnBean 和 @ConditionalOnMissingBean 不会阻止 @Configuration 类的创建，在类级别使用那些conditions跟使用注解标记每个@Bean方法是等价的。 Property 条件@ConditionalOnProperty注解可以根据一个Spring Environment 属性来决定是否包含配置，使用 prefix 和 name 属性指定要检查的配置。默认情况下，任何存在的主要不是 false 的属性都会匹配，你也可以使用havingValue 和 matchIfMissing属性创建更高级的检测。 matchIfMissing 当配置文件不存在 prefix.name 值是默认为true还是false，true任务匹配成功havingValue 是一个字符串 与 文件中配置的prefix.name 进行equal 比较 1@ConditionalOnProperty(prefix = &quot;example.service&quot;, value = &quot;enabled&quot;, matchIfMissing = true)，当配置文件中example.service.enabled=true时进行自动配置，如果没有设置此值就默认使用matchIfMissing对应的值 Resource条件@ConditionalOnResource 注解只在特定资源出现时才会包含配置，可以使用常见的Spring约定命名资源，例如file://home/user/test.dat Web Application条件@ConditionalOnWebApplication 和 @ConditonalOnNotWebApplication 注解可以根据应用是否为’web应用’来决定是否包含配置，web应用是任何使用Spring WebApplicationContext，定义一个 session 作用域，或有一个 StandardServeltEnvironment的应用。 SpEL表达式条件@ConditionalOnExpression 注解可以根据SpEL表达式结果来决定是否包含配置。","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blog.shicc.top/tags/Spring-Boot/"}]},{"title":"CentOS SSH免密码登陆","slug":"CentOS SSH免密码登陆","date":"2018-12-13T10:22:05.000Z","updated":"2019-01-17T14:08:52.231Z","comments":true,"path":"CentOS SSH免密码登陆.html","link":"","permalink":"http://blog.shicc.top/CentOS SSH免密码登陆.html","excerpt":"","text":"Centos SSH免密码登陆1.在客户机创建一对密钥文件,包括公钥文件(~/.ssh/id_rsa.pub),私钥文件(~/.ssh/id_rsa) 2.把公钥放到服务器上（~/.ssh/authorized_keys）,在使用ssh登录时，ssh程序会发送私钥去和服务器上的公钥做匹配。如果匹配成功就可以自动登录了。 服务器配置 修改sshd配置文件(/etc/ssh/sshd_config) 1PubkeyAuthentication yes 配置authorized_keys文件若 ~/.ssh/authorized_keys 不存在,则建立.ssh文件夹和authorized_keys文件. 重启sshd 1$ /etc/init.d/sshd restart 注意1) .ssh目录的权限必须是7002) .ssh/authorized_keys文件权限必须是600","categories":[],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://blog.shicc.top/tags/CentOS/"}]},{"title":"CentOS下Redis安装","slug":"Centos Reids 安装","date":"2018-12-03T10:22:05.000Z","updated":"2018-12-03T11:08:50.229Z","comments":true,"path":"Centos Reids 安装.html","link":"","permalink":"http://blog.shicc.top/Centos Reids 安装.html","excerpt":"","text":"Redis 版本号约定安装Redis需要知道自己需要哪个版本，有针对性的安装，比如如果需要redis GEO这个地理集合的特性，那么redis版本就不能低于3.2版本，由于这个特性是3.2版本才有的。另外需要注意的是，Redis约定次版本号（即第一个小数点后的数字）为偶数的版本是稳定版（如2.8版、3.0版），奇数版本是非稳定版（如2.7版、2.9版），生产环境下一般需要使用稳定版本。 下载安装包1wget http://download.redis.io/releases/redis-4.0.2.tar.gz 可从http://download.redis.io/releases/查询自己所需要的版本。 解压安装包并下载1234tar -zxvf redis-4.0.2.tar.gzcd redis-4.0.2makemake install Redis 启动1./redis-server ./redis.conf 通过参数daemonize设置redis后台启动 Redis 关闭1redis-cli SHUTDOWN 或者1kill -9 进程号","categories":[],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://blog.shicc.top/tags/CentOS/"},{"name":"Redis","slug":"Redis","permalink":"http://blog.shicc.top/tags/Redis/"}]},{"title":"Socket 长连接","slug":"Java-Socket-长连接","date":"2018-12-03T10:22:05.000Z","updated":"2018-12-03T11:01:50.259Z","comments":true,"path":"Java-Socket-长连接.html","link":"","permalink":"http://blog.shicc.top/Java-Socket-长连接.html","excerpt":"","text":"最近再做根据 Cmpp 协议对接一个短信网关接口。考虑到需要频繁的与网关服务器进行数据交互，因此使用长连接。 如何区分长连接,短连接 ?所谓短连接就是建立一次tcp握手成功后进行数据交互，交互完成主动或者关闭tcp。 主动关闭 一般就是关闭socket或者关闭socket的 in ou流。被动关闭会受限操作系统的配置。比如建立tcp成功之后的一段时间若无数据交互，则操作系统会主动关闭这次tcp连接。 长连接，其实就是就是在建立一次tcp成功之后，通过一定的心跳机制来保证tcp链路一直建立而不释放。具体的长连接也需要Server的支持。 Java Socket 长连接 创建一个Socket12345Socket msgSocket = new Socket();SocketAddress socAddress = new InetSocketAddress(msgConfig.getIsmgIp(), msgConfig.getIsmgPort());SocketAddress locAddress = new InetSocketAddress(InetAddress.getLocalHost(), msgConfig.getIsLocalPort());msgSocket.bind(locAddress);msgSocket.connect(socAddress, SOCKET_TIME_OUT); 创建客户端socket 有多种方式，最常用的方式为Socket msgSocket = new Socket(msgConfig.getIsmgIp(), msgConfig.getIsmgPort(), InetAddress.getLocalHost(), msgConfig.getIsLocalPort());,但通过这个方式我发现 Socket 会自动关闭。 后来尝试使用上面的方法创建一个Socket 并通过 connect 设置超时时间，然后在超时时间内进行一次心跳交互，可以达到http长连接。 如何判断是否为长连接若http协议可以根据http head 中的 keep-alive 判断是否为长连接。对于tcp或者socket，我们再与服务器建立长连接时会开辟一个端口，数据会通过这个端口与服务器进行数据交互，因此我们可以监控这个端口，查看这个端口的状态。123lsof -i: portjava 2240 root 154u IPv4 205709 0t0 TCP xxx:port-&gt; remote_ip:remote_ip (ESTABLISHED) TCP 端口说明TCP 协议规定，对于已经建立的连接，网络双方要进行四次握手才能断开成功，如果缺少了其中某个步骤，将会使连接处于假死状态，连接本身占用的资源也不会被释放。CLOSE_WAIT 和 TIME_WAIT 这两个TCP状态值得我们关注一下 LISTENING 状态FTP 服务启动后会处于侦听(LISTENING) 状态 ESTABLISTENED 状态ESTABLISTENED的意思是建立连接，表示两台机器正在通信 CLOSE_WAIT对方主动关闭连接或者网络异常导致连接中断，这是我方的状态会变成CLOSE_WAIT,此时我方要调用 close() 来使得连接正确关闭。 TIME_WAIT我方主动调用 close() 断开连接，收到对方确认后状态会变为 TIME_WAIT。TCP 协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT 状态的连接占用资源不会被内存释放，所以作为服务器，再可能的情下，尽量不要主动断开连接，减少TIME_WAIT状态造成的资源浪费。 SYN_SENT 状态SYN_SENT 状态表示请求连接，当你要访问其他的计算机的服务时首先要发个同步信号给该端口，此时的状态为SYN_SENT，如果连接成功了就变成 ESTABLISTENED,此时SYN_SENT状态非常短暂。 根据TCP协议定义的3次握手断开连接规定,发起socket主动关闭的一方 socket将进入TIME_WAIT状态,TIME_WAIT状态将持续2个MSL(Max Segment Lifetime),在Windows下默认为4分钟,即240秒,TIME_WAIT状态下的socket不能被回收使用. 具体现象是对于一个处理大量短连接的服务器,如果是由服务器主动关闭客户端的连接,将导致服务器端存在大量的处于TIME_WAIT状态的socket, 甚至比处于Established状态下的socket多的多,严重影响服务器的处理能力,甚至耗尽可用的socket,停止服务. TIME_WAIT是TCP协议用以保证被重新分配的socket不会受到之前残留的延迟重发报文影响的机制,是必要的逻辑保证. 常用tcp命令123netstat netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos;","categories":[],"tags":[{"name":"长连接","slug":"长连接","permalink":"http://blog.shicc.top/tags/长连接/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://blog.shicc.top/tags/TCP-IP/"},{"name":"socket","slug":"socket","permalink":"http://blog.shicc.top/tags/socket/"}]},{"title":"Log4j MDC","slug":"Log4j-MDC","date":"2018-11-22T05:11:22.000Z","updated":"2018-12-03T10:19:55.663Z","comments":true,"path":"Log4j-MDC.html","link":"","permalink":"http://blog.shicc.top/Log4j-MDC.html","excerpt":"","text":"Log4j MDC问题在项目中需要分类收集处理日志信息，使用log4j的MDC线程中添加分类信息。不过最近却出现信息记录错误的情况，具体来说就是会出现本来属于下一个分类的一部分信息莫名的记录到上一个分类的日志文件中了。 问题原因分析MDC 需要在完成后被重置，或者说清空。因为MDC是绑定线程的，所以，在大多数简单的使用的情况下，例如在服务器端接受请求的入口处，设置一个MDC信息，如果服务器这个程序任务的程序结束后会被丢弃，那么也不会出现什么问题，但是如果是一个线程池，池的线程会被重复利用的情况下，如果你没有结束后清楚MDC的信息，那么在下次设置之前，上次设置以后的这段日志，就会出现数据错乱的情况。 解决方法在log4j 1.2.16以后的版本，MDC直接提供了clear() 方法即：1MDC.clear() 或者手动清理MDC12MDC.getContext().clear();// 需要校验一下MDC.getContext() 不为null tip当我们在项目中使用 ThreadLocal 时，在一个线程结束时也需要清空 ThreadLocal中的数据，否则也可能会出现上述情况。","categories":[],"tags":[]},{"title":"Redlock实现分布式锁","slug":"Redlock实现分布式锁","date":"2018-11-11T02:41:34.000Z","updated":"2018-12-03T10:19:55.664Z","comments":true,"path":"Redlock实现分布式锁.html","link":"","permalink":"http://blog.shicc.top/Redlock实现分布式锁.html","excerpt":"","text":"","categories":[],"tags":[]},{"title":"MySQL 安装","slug":"MySQL 安装","date":"2018-09-06T03:37:01.000Z","updated":"2018-12-03T10:19:55.664Z","comments":true,"path":"MySQL 安装.html","link":"","permalink":"http://blog.shicc.top/MySQL 安装.html","excerpt":"","text":"MySQL 安装Windons 下MySQL的安装方式一般分为两种，一种基于 Exe 可执行文件的安装，另外一种是解压安装。 解压安装将下载下来的mysql进行zip解压。 复制 my-default.ini 并改名为 my.ini，新建 data 和 log 两个文件夹看一个保存数据，一个保存log。 修改 my.ini 下的文件内容 执行 mysqld.exe install mysql 将mysql注册到window service 中 执行 mysqld --initialize --console 初始化mysql data，并在控制台输出默认密码 执行 net start mysql 启动mysql 使用初始密码进入mysql 执行 set password = PASSWorD(&quot;Admin123456&quot;) 修改 mysql root 用户的密码","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.shicc.top/tags/MySQL/"}]},{"title":"GC 优化","slug":"GC 优化","date":"2018-09-05T06:09:40.000Z","updated":"2018-12-03T10:19:55.661Z","comments":true,"path":"GC 优化.html","link":"","permalink":"http://blog.shicc.top/GC 优化.html","excerpt":"","text":"GC 优化JVM监控可以使用以下衡量标准 总内存使用情况（MB）：即JVM使用的总内存。如果JVM使用了所有可用内存，这项指标可以衡量底层操作系统的整体性能。 堆内存使用（MB）：即JVM为运行的Java应用所使用的对象分配的所有内存。不使用的对象通常会被垃圾回收器从堆中移除。所以，如果这个指数增大，表示你的应用没有把不使用的对象移除或者你需要更好的配置垃圾回收器的参数。 非堆内存的使用（MB）：即为方法区和代码缓存分配的所有内存。方法区是用于存储被加载的类的引用，如果这些引用没有被适当的清理，永生代池会在每次应用被重新部署的时候都会增大，导致非堆的内存泄露。这个指标也可能指示了线程创建的泄露。 池内总内存（MB）：即JVM所分配的所有变量内存池的内存和（即除了代码缓存区外的所有内存和）。这个指标能够让你明确你的应用在JVM过载前所能使用的总内存。 线程：即所有有效线程数。举个例子，在Tomcat服务器中每个请求都是一个独立的线程来处理，所以这个衡量指标可以表示当前有多少个请求数，是否影响到了后台低权限的线程的运行。 类：即所有被加载的类的总数。如果你的应用动态的创建很多类，这可能是内存泄露的一个原因。 GC 优化的目的： 将老年代的对象数量将至最低 减少Full GC 的执行时间 老年代GC相对于新生代GC更耗时 Full GC 的执行时间币 Minor GC 要长的多 老年代空间过小会导致 Full GC 频率增加或者 内存溢出老年代空间过大会导致 Full GC 时间过长 GC 监控工具 jstat 和 HPJMeter1jstat -gcutil 1234jstat -gccapacity # 检查内存用量情况NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC PGCMN PGCMX PGC PC YGC FGC212992.0 212992.0 212992.0 21248.0 21248.0 170496.0 1884160.0 1884160.0 1884160.0 1884160.0 262144.0 262144.0 262144.0 262144.0 54 5 堆内存分配 1-Xms -Xmx 非堆内存分配永久保存的区域， 用于存放Class和Meta信息，Class在被Load的时候被放入该区域。 三种内存溢出异常 OutOfMemoryError: Java heap space 堆溢出内存溢出主要存在的问题就是出现在这个情况中。当在JVM中如果98%的时间是用于GS切可以用的Heap size 不足2%的时候将抛出此异常信息 OutOfMemoryError: PermGen space 非堆溢出(永久保存区域溢出) 这种错误常见在web服务器对jsp进行 pre compile 的时候。如果你的WEB APP 下毒用了大量第三方jar，其大小超过了jvm默认的大小(4M) 那么就会产生此错误信息。 如果web app 用了大量的第三方jar或者应用有太多的class文件而恰好MaxPermSize设置较小，超出了也会导致这块内存的占用过多造成溢出，或者 tomcat 热部署时不清除前面加载的环境，只会将 context 更改为新部署的，非堆存的内容就越来越多。 OutOfMemoryError: unable to create new native thread 无法创建新的线程 这种现象比较少见，也比较奇怪，主要和jvm与系统内存的比例有关，这种怪事是因为jvm已经被系统分配了大量的内存，并且它至少要占用可用内存的一半。 Java Heap 分为3个区： Young Old Permanent Jvm 有2个GC线程：第一个线程负责回收Heap的Young区第二个线程在Heap不足时，遍历Heap，将Young区升级为Older区，Older区的大小等于 -Xmx 减去 -Xmn,不能将-Xms的值设的过大，因为第二个线程被迫运行会降低 JVM 的性能 GC 优化的经验之谈 JVM 最好将 -Xms 和 -Xmx 设为相同的值。为了优化GC，最好让 -Xmn值约等于-Xmx 的 1/3 . 一个 GUI 程序最好是每 10到20秒间执行一个GC，每次在半秒之内完成 GC 分析1234567ps -ef|grep java #获取进程号jstat -gc 进程号# 间隔固定时间打印jstat -gc 进程号 2000 20 # 每隔2000ms输出该进程的gc情况，一共输出20此 GC 参数 -XX:+PrintGC 输出GC日志 -XX:+PrintGCDetails 输出GC的详细日志 -XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式） -XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如年月日） -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息 -Xloggc:../logs/gc.log 日志文件的输出路径 Tomcat 设置示例123456JAVA_OPTS=&quot;-server -Xms2000m -Xmx2000m -Xmn800m -XX:PermSize=64m -XX:MaxPermSize=256m -XX:SurvivorRatio=4-verbose:gc -Xloggc:$CATALINA_HOME/logs/gc.log -Djava.awt.headless=true -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Dsun.rmi.dgc.server.gcInterval=600000 -Dsun.rmi.dgc.client.gcInterval=600000-XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=15&quot;","categories":[],"tags":[{"name":"GC","slug":"GC","permalink":"http://blog.shicc.top/tags/GC/"}]},{"title":"Unix IO","slug":"Unix IO","date":"2018-08-09T02:27:50.000Z","updated":"2018-12-03T10:19:55.670Z","comments":true,"path":"Unix IO.html","link":"","permalink":"http://blog.shicc.top/Unix IO.html","excerpt":"","text":"一个 Linux 文件就是一个 m个字节的序列。所有的I/O设备（例如网络、磁盘和终端）都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。这种将设备优雅地映射为文件的方式，允许Liunx内核引出一个简单、低级的应用接口，称为 Unix I/O ，这使得所有的输入和输出都能以一种统一且一致的方式来执行： 打开文件。一个应用程序通过要求内核打开相应的文件，来宣告它想要访问一个I/O设备。内核返回一个小的非负整数，叫做描述符，它在后续对此文件的所有操作中标识这个文件。内核记录有关这个打开文件的所有信息。应用程序只需要记住这个描述符。 Liunx shell 创建的每个进程开始时都有三个打开的文件：标准输入(描述符为0)、标准输出(描述符为1)和标准错误(描述符为2)。 改变当前文件的文件位置。对于每个打开的文件，内核保持这一个文件位置k，初始为0.这个文件位置是从文件开头开始的字节偏移量。应用程序能够通过执行 seek操作，显式地设置文件的当前位置为k。 读写文件。一个读操作就是从文件复制 n&gt;0 个字节到内存。从当前文件位置k开始，然后将k添加到k+n。给定一个大小为m字节的文件，当k&gt;=m 时执行行读写操作会触发一个称为 end-of-file(EOF)的条件，应用程序能检测到这个条件。在文件结尾处并没有明确的”EOF符号”。 类似地，写操作就是从内存复制 n&gt;0 个字节到一个文件，从当前文件位置k开始，然后更新k。 关闭文件。当应用完成了对文件的访问之后，它就通知内核关闭这个文件。作为响应，内核释放文件打开时创建的数据结构，并将这个描述符恢复到可用的描述符池中。无论一个进程因为何中原因终止时，内核都会关闭所有打开的文件并释放它们的内存资源。 每个Liunx文件都有一个类型（type）来表明它在系统中的角色： 普通文件 目录 套接字(socket) 是用来与另外一个进行跨网络通信的文件。 命名通道 符号链接 字符 块设备 存储单位二进制序列用以表示计算机、电子信息数据容量的量纲，基本单位为字节B，字节向上分别为KB、MB、GB、TB，每级为前一级的1024倍，比如1KB=1024B,1M=1024KB.位 bit(比特)：存放一个二进制数，即0或1，最小的存储单位。英文缩写：b(固定小写)字节byte：8个二进制位为一个字节(B),最常用的单位。","categories":[],"tags":[{"name":"Unix IO","slug":"Unix-IO","permalink":"http://blog.shicc.top/tags/Unix-IO/"}]},{"title":"Nginx负载均衡策略","slug":"nginx-负载策略","date":"2018-08-08T02:43:05.000Z","updated":"2018-12-03T10:19:55.675Z","comments":true,"path":"nginx-负载策略.html","link":"","permalink":"http://blog.shicc.top/nginx-负载策略.html","excerpt":"","text":"Nginx负载均衡策略轮询（默认）每个web请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。1234upstream nginxDemo&#123; server 127.0.0.1:8081; server 127.0.0.1:8082;&#125; 最少链接web 请求会被转发到连接数最少的服务器上。123least_conn;server 127.0.0.1:8081;server 127.0.0.1:8082; weight 权重指定轮询几率，weight和访问比率成正比，weight默认是1。服务器A和服务器B的访问比例为：2-1，比如有3个请求，前两个会访问A，第三个访问B，其他的规则和轮询一样。1234upstream nginxDemo&#123; server 127.0.0.1:8081 weight=2; server 127.0.0.1:8082;&#125; ip_hash每个请求按访问ip的hash值分配，这样客户端连续的Web请求都会被分配到同一服务器进行处理，可以解决session的问题。当后台服务器宕机时，会自动跳转到其他服务器。12345upstream nginxDemo&#123; ip_hash; server 127.0.0.1:8081 weight=2; server 127.0.0.1:8082 ;&#125; 基于weight的负载均衡和基于 ip_hash 的负载均衡器可以组合在一起使用。 url_hash(第三方)url_hash 是nginx的第三方模块，nginx本身不支持，需要引入第三方组件。nginx 按访问 url 的hash 结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器，文件服务器，静态资源服务器时比较有效。缺点：当后端服务器宕机时，url_hash 不会自动跳转到其他缓存服务器，而返回给用于一个503错误。 12345upstream nginxDemo&#123; server 127.0.0.1:8081; server 127.0.0.1:8082; hash $request_url&#125; fair(第三方)按后端服务器的响应时间来分配请求，响应时间短的优先分配12345upstream nginxDemo&#123; server 127.0.0.1:8081; server 127.0.0.1:8082; fair;&#125; 负载均衡后 Session 管理 tomcattomcat 本身已支持该功能。但这种处理方式，不建议在大的集群中使用。tomcat 的会话复制为两种： 123&lt;Manager className=&quot;org.apache.catalina.ha.session.BackupManager&quot; expireSessionsOnshutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot; mapSendOptions=&quot;6&quot;&gt;&lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnshutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot; mapSendOptions=&quot;6&quot;&gt; 全局复制(DeltaManager):复制会话中的变更信息到集群中的所有其他节点。 非全局复制(BackupManger):它会吧session复制给一个指定的备份节点。 Session 共享session共享的实现方式有很多种，比人们 memcached，Redis，DB等。其核心思想是修改 tomcat 的session存储机制，使之能够session序列化，然后存放到memcached中。实现方式： Tomcat+Nginx+MSM+memcached 相关jar包放到tomcat/lib目录下：Java memcached客户端：spymemcached.jarMSM： 核心包，memcached-session-manager-{version}.jar Tomcat版本对应的jar包：memcached-session-manager-tc{tomcat-version}-{version}.jar序列化工具包：可选kryo（据说效率比较快），javolution，xstream等，不设置时使用jdk默认序列化。 Tomcat文件tomcatconfcontext.xml添加： 黏性处理方式： 123&lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.2.61:11211,n2:192.168.2.66:11211&quot; requestUriIgnorePattern=&quot;.*.(ico|png|gif|jpg|css|js)$&quot;transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot;/&gt; 非黏性处理方式： 1&lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.2.61:11211,n2:192.168.2.66:11211&quot; sticky=&quot;false&quot; lockingMode=&quot;auto&quot; requestUriIgnorePattern=&quot;.*.(ico|png|gif|jpg|css|js)$&quot; sessionBackupAsync= &quot;false&quot; sessionBackupTimeout= &quot;100&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot;/&gt; 参考资料Nginx+Tomcat 配置负载均衡集群","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.shicc.top/tags/Nginx/"},{"name":"负载均衡策略","slug":"负载均衡策略","permalink":"http://blog.shicc.top/tags/负载均衡策略/"}]},{"title":"分布式ID解决方案","slug":"分布式ID解决方案","date":"2018-08-06T03:48:40.000Z","updated":"2018-12-03T10:19:55.678Z","comments":true,"path":"分布式ID解决方案.html","link":"","permalink":"http://blog.shicc.top/分布式ID解决方案.html","excerpt":"","text":"分布式ID解决方案可供选择的分布式ID方案 UUID 优点： - 简单，代码方便 - 生成ID性能非常好，基本不会有性能问题 - 全球唯一，永不重复 缺点： - 没有排序，无法保证趋势递增 - UUID存的是字符串，查询效率比较低 - UUID 存储空间以及数据传输数据量大 基于数据库的自增ID 基于 Redis 的自增ID使用Redis的原子操作 INCR和INCRBY来实现比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+自增长号 优点： - 不依赖于数据库，灵活方便，且性能优于数据库 - 数字ID天然排序，对分页或者排序的结果有帮助 基于MongoDB的ObjectId Snowflake twitter 开发的一套全局唯一ID生成服务 Snowflake 41位的时间序列(精确到毫秒，41位的长度可以使用69年) 10位的机器标识(10为的长度最多支持1024个节点部署) 12位的计数序号 类snowflake算法 百度的uid-generator 美团Leaf 本人比较偏向于基于Redis的方式生成自增ID。现在的项目基本都会引入Reids做缓存中间件，因此不会因为额外的组件。生产环境中的Reids，基本上都基于主从，或者集群可以防止单点故障。同时代码实现也比较简单。比如ID = YYYYMMDD + 自增长号。后台使用两个字段值来作为ID，排序时先根据时间，再根据自增长ID进行排序。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://blog.shicc.top/tags/分布式/"}]},{"title":"MessageDigest 使用注意，并发问题","slug":"MD5 多线程计算错误","date":"2018-07-11T03:48:40.000Z","updated":"2018-12-03T10:19:55.664Z","comments":true,"path":"MD5 多线程计算错误.html","link":"","permalink":"http://blog.shicc.top/MD5 多线程计算错误.html","excerpt":"","text":"MessageDigest 使用注意，并发问题 Message Digest Algorithm MD5（中文名为消息摘要算法第五版）为计算机安全领域广泛使用的一种散列函数，用以提供消息的完整性保护。该算法的文件号为RFC 1321（R.Rivest,MIT Laboratory for Computer Science and RSA Data Security Inc. April 1992）。 产生错误原因因为这些常用的工具类之前都写好了，用的时候没有多想就直接Copy过来了，请求是并发的，刚刚开始的时候，并发请求较少（1-2）个，没有出现什么问题，后来请求3-4个同时发的时候，服务端偶尔抛出MD5值验证错误的信息，后来翻看了MD5工具类之后才发现，原来这个类写的方式并不支持并发，MessageDigest被声明为成员变量，多线程环境下会共享同一个MessageDigest对象 MessageDigest源码 123456789/** * Updates the digest using the specified array of bytes. * * @param input the array of bytes. */public void update(byte[] input) &#123; engineUpdate(input, 0, input.length); state = IN_PROGRESS;&#125; 调用了engineUpdate方法，此方法进行一个更新操作。1Updates the digest using the specified array of bytes, starting at the specified offset. 然后state属性的状态就被改变了，表明当前计算正在处理过程中。 state默认属性1private int state = INITIAL; 然后需要调用MessageDigest.digest()方法计算哈希值123456789101112/** * Completes the hash computation by performing final operations * such as padding. The digest is reset after this call is made. * * @return the array of bytes for the resulting hash value. */public byte[] digest() &#123; /* Resetting is the responsibility of implementors. */ byte[] result = engineDigest(); state = INITIAL; return result;&#125; 到这里已经完成了MD5值的计算，state属性恢复初始状态，如果想要重用MessageDigest对象，还需要调用MessageDigest.reset()方法进行重置，以免这次计算数据会对下一次的计算造成影响，从而导致计算结果错误。 而我所遇到的问题就是，在MessageDigest在多线程的环境下，Thread-1的计算还没有完成的情况下，Thread-2又开始使用该MessageDigest对象进行下一次的计算，Thread-2修改了MessageDigest的状态，Thread-1使用被修改过后的MessageDigest进行计算，从而导致了计算结果错误。 解决方法pom.xml12345&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt;&lt;/dependency&gt; 123byte[] md5Value = DigestUtils.md5(date);String md5Value = DigestUtils.md5Hex(date);","categories":[],"tags":[{"name":"MD5","slug":"MD5","permalink":"http://blog.shicc.top/tags/MD5/"},{"name":"多线程","slug":"多线程","permalink":"http://blog.shicc.top/tags/多线程/"},{"name":"MessageDigest","slug":"MessageDigest","permalink":"http://blog.shicc.top/tags/MessageDigest/"}]},{"title":"Java 动态代理","slug":"Java 动态代理","date":"2018-07-04T04:48:40.000Z","updated":"2018-12-03T10:19:55.661Z","comments":true,"path":"Java 动态代理.html","link":"","permalink":"http://blog.shicc.top/Java 动态代理.html","excerpt":"","text":"反射反射的入口是名称为Class的类 代理静态代理动态代理 Java SDK cglib 123456public static void main(String[] args) &#123; IService realService = new RealService(); IService proxyService = (IService) Proxy.newProxyInstance(IService.class.getClassLoader(), new Class&lt;?&gt;[] &#123; IService.class &#125;, new SimpleInvocationHandler(realService)); proxyService.sayHello();&#125; CGLIB 与 Java SDK 动态代理的区别Java SDK 动态代理局限在于，他只能为接口创建代理，返回的代理对象也只能转换到某个接口类型，如果一个类没有接口，或者希望代理非接口中定义的方法，那就没有办法了。Java SDK 代理面向的是一组接口，它为这些接口创建了一个实现类，接口的具体实现逻辑是通过自定义的InvocationHandler实现的，这个实现是自定义的，也就是说，其背后都不一定有真正被代理的对象，也可能多个实际对象，根据情况动态选择。cglib代理面向的是一个具体的类，它动态创建了一个新类，也继承了改类，重写了其方法。从代理的角度看，Java SDK代理的是对象，需要先有一个实际对象，自定义的InvocationHandler引用该对象，然后创建一个代理类和代理对象，客户端访问的是代理对象，代理对象最后再代用实际对象的方法，cglib代理的是类，创建的对象只有一个。 动态代理的优点使用动态代理可以编写通用的代理逻辑，用于各种类型的被代理对象，而不用每个被代理的类型都创建一个静态代理类。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://blog.shicc.top/tags/Java/"},{"name":"动态代理","slug":"动态代理","permalink":"http://blog.shicc.top/tags/动态代理/"}]},{"title":"Spring Cloud Feign","slug":"Spring Cloud Feign","date":"2018-07-04T04:48:40.000Z","updated":"2018-12-03T10:19:55.667Z","comments":true,"path":"Spring Cloud Feign.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Feign.html","excerpt":"","text":"Ribbon 配置Spring Cloud Feign 的客户端负载均衡是通过 Spring Cloud Ribbon 实现的，所以可以直接通过配置Ribbon客户端的方式来自定义各个服务客户端调用的参数。 全局12ribbon.ConnectTimeout=500ribbon.ReadTimeout=5000 单位毫秒 指定服务配置1&lt;client&gt;.ribbon.key = value == @FeignClient 中的服务名称 Ribbon 重试机制1SERVICE.ribbon.MaxAutoRetries=1 重试策略先尝试访问首选实例一次，失败后才更换实例方法，更换实例访问的次数通过 ribbon.MaxAutoRetriesNextServer 参数设置。MaxAutoRetries 单个实例的最大尝试次数，MaxAutoRetriesNextServer更换实例尝试的最大次数 TIPRibbon的超时与Hystrix的是超时是两个概念，Hystrix 的是超时时间需要大于Ribbon的超时时间，否则Hystrix命令超时后，该命令直接熔断，重试机制也就没有意义。 Hystrix 配置Hystrix 实现服务降级 全局配置1hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds = 5000 单位毫秒 12feign.hystrix.enabled = falsehystrix.command.defauld.exectuion.timeout.enabled=false 关闭Feign 客户端的 Hystrix 功能 指定命令配置采用 hystrix.command.&lt;commandKey&gt; 作为前缀 其他配置请求压缩12345678# 开启对请求与相应的GZIP压缩，减少通行过程中的性能损耗feign.compression.request.enabled=truefeign.compression.response.enaled=true# 配置内容指定了压缩的请求数据类型，设置请求压缩的大小下限，只有超过这个大小的请求才会对其进行压缩feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048 日志配置","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Spring Cloud Feign","slug":"Spring-Cloud-Feign","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Feign/"}]},{"title":"分表分库","slug":"分表分库","date":"2018-07-04T04:48:40.000Z","updated":"2018-12-03T10:19:55.678Z","comments":true,"path":"分表分库.html","link":"","permalink":"http://blog.shicc.top/分表分库.html","excerpt":"","text":"","categories":[],"tags":[{"name":"分表分库","slug":"分表分库","permalink":"http://blog.shicc.top/tags/分表分库/"},{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"http://blog.shicc.top/tags/Sharding-JDBC/"}]},{"title":"Spring Aop 源码学习","slug":"Spring Aop 源码学习","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.666Z","comments":true,"path":"Spring Aop 源码学习.html","link":"","permalink":"http://blog.shicc.top/Spring Aop 源码学习.html","excerpt":"","text":"Spring Aop 源码学习入口1AopNamespaceHandler.java","categories":[],"tags":[{"name":"Spring Aop","slug":"Spring-Aop","permalink":"http://blog.shicc.top/tags/Spring-Aop/"},{"name":"Spring Cloud Zipkin","slug":"Spring-Cloud-Zipkin","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Zipkin/"}]},{"title":"Spring Cloud Actuator","slug":"Spring Cloud Actuator","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.666Z","comments":true,"path":"Spring Cloud Actuator.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Actuator.html","excerpt":"","text":"Spring Cloud Actuator为Spring Boot 构建的应用提供一系类用于监控的断点。 原生断点spring-boot-starter-actuator 模块中已经实现的一些原生端点 应用配置类： 获取应用程序中加载的应用配置、环境变量、自动化配置报告等于Spring Boot 应用密切相关的配置类信息。 度量指标类： 获取应用程序运行过程中用于监控的度量指标，比如内存信息、线程池信息、http 请求统计等 操作控制类： 提供了对应用的关闭等操作可供您","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Spring Cloud Actuator","slug":"Spring-Cloud-Actuator","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Actuator/"}]},{"title":"Spring Cloud Eureka","slug":"Spring Cloud Eureka","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.667Z","comments":true,"path":"Spring Cloud Eureka.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Eureka.html","excerpt":"","text":"Spring Cloud Eureka","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Eureka/"}]},{"title":"Spring Cloud Config","slug":"Spring Cloud Config","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.666Z","comments":true,"path":"Spring Cloud Config.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Config.html","excerpt":"","text":"Spring Cloud Config自定义参数application.yml 文件123app: name: aa pwd: 123456 java 文件12345678910@Componentpublic class Test&#123; @Value(&quot;$&#123;app.name&#125;&quot;) private String name; @Value(&quot;$&#123;app.pwd&#125;&quot;) private String pwd&#125; @Value 注解加载属性值的时，可支持两种表达方进行配置 PlaceHolder方式，格式为 ${…},大括号内为 PlaceHolder SpEL 表达式，格式为 #{….}, 大括号内为SpEL表达式 参数引用配置文件中可以通过 PlaceHolder 的方式进行引用。 加载顺序 命令行中传入的参数 SPRING_APPLICATION_JSON 中的属性，SPRING_APPLICATION_JSON 是以json 格式配置在系统环境中的内容 java:comp/env 中的JNDI属性 Java的系统属性，可以通过System.getProperties()获得的内容。 操作系统的环境变量 通过random.* 配置的随机属性。 位于当前应用jar包之外，针对不同 {profile} 环境的配置文件内容。 位于当前应用jar包之内，针对不同｛profile｝环境的配置文件内容。 位于当前应用jar包之外的application.properties配置内容。 位于当前应用的jar包之内的application.properties的配置内容。 在@Configuration 注解修改的类中，通过 @PropertySource 注解定义的属性。 应用默认属性，使用SpringApplication.setDefauldProperties定义的内容。 优先级按上面的的顺序由高到底，数字越小优先级越高。在第7项和第9项都是从应用 jar 包之外读取配置文件，所以，实现外部化配置的原理就是从此切入，为其指定外部配置文件的加载位置来取代jar包内的配置内容。 TODO写一段测试脚本，显示 配置内容的加载顺序，覆盖顺序，以及所有配置信息的内容。","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Spring Cloud Config","slug":"Spring-Cloud-Config","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Config/"}]},{"title":"Spring Cloud Ribbon","slug":"Spring Cloud Ribbon","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.667Z","comments":true,"path":"Spring Cloud Ribbon.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Ribbon.html","excerpt":"","text":"Spring Cloud RibbonRibbonLoadBalancerClient","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Spring Cloud Ribbon","slug":"Spring-Cloud-Ribbon","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Ribbon/"}]},{"title":"Spring Aop 源码学习","slug":"Spring 源码学习","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.668Z","comments":true,"path":"Spring 源码学习.html","link":"","permalink":"http://blog.shicc.top/Spring 源码学习.html","excerpt":"","text":"Spring 源码学习入口1ClassPathXmlApplicationContext.java","categories":[],"tags":[{"name":"Spring Aop","slug":"Spring-Aop","permalink":"http://blog.shicc.top/tags/Spring-Aop/"},{"name":"Spring Cloud Zipkin","slug":"Spring-Cloud-Zipkin","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Zipkin/"}]},{"title":"Spring Cloud Zipkin","slug":"Spring Cloud Zipkin","date":"2018-07-04T03:48:40.000Z","updated":"2018-12-03T10:19:55.668Z","comments":true,"path":"Spring Cloud Zipkin.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud Zipkin.html","excerpt":"","text":"Spring Cloud ZipkinZipkin 集成zipkin 项目1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 普通程序项目123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient@EnableSchedulingpublic class AdminBootstrap &#123; public static void main(String[] args) &#123; try &#123; new SpringApplicationBuilder(AdminBootstrap.class).web(true).run(args); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;spring: application: name: trace-2 zipkin: base-url: http://10.3.185.26:8480 sleuth: sampler: percentage: 1.0 Zipkin 集成 RabbitMQzipkin 项目1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 普通程序项目123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--zipkin链路日志追踪 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;spring: application: name: trace-2# zipkin:# base-url: http://10.3.185.26:8480 sleuth: sampler: percentage: 1.0 jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_null rabbitmq: host: 10.203.105.68 port: 5672 username: test password: test 遇到的问题","categories":[],"tags":[{"name":"Spring Cloud Zipkin","slug":"Spring-Cloud-Zipkin","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Zipkin/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"}]},{"title":"liunx 性能分析","slug":"liunx 性能分析","date":"2018-07-03T07:41:33.000Z","updated":"2018-12-03T10:19:55.672Z","comments":true,"path":"liunx 性能分析.html","link":"","permalink":"http://blog.shicc.top/liunx 性能分析.html","excerpt":"","text":"uptime12$uptime07:13:53up8days,19min, 1user, load average: 1.98,2.15,2.21 load average: 1.98,2.15,2.21 一分钟内的负载，5分钟内的负载，15分钟内的负载。 为了进一步理解系统负载，需要做一些假设。假设系统负载如下：23:16:49 up 10:49, 5 user, load average: 1.00, 0.40, 3.35在单核系统中意味着： CPU 被充分利用（100%）；最近的 1 分钟有 1 个进程在运行。 CPU 有 60% 处于空闲状态；在最近的 5 分钟没有进程等待 CPU 时间。 CPU 平均过载了 235%；最近的 15 分钟平均有 2.35 个进程在等待 CPU 时间。在双核系统中意味着： 有一个 CPU 处于完全空闲状态，另一个 CPU 被使用；最近的 1 分钟没有进程等待 CPU 时间。 CPU 平均 160% 处于空闲状态；最近的 5 分钟没有进程等待 CPU 时间。 CPU 平均过载了 135%；最近的 15 分钟有 1.35 个进程等待 CPU 时间。 压测分析步骤 优化服务器本省的TCP信息 tcp 端口的释放时间 查看内存，cpu，硬盘的IO 内存 Free -h 查看 buffers/cache 的值，buffers/cache 表示实际占用的值 iostat top 分析服务器当前的并发数，文件打开数 netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’ Liunx 内核优化vim /etc/security/limits.conf soft nproc 10240 hard nproc 16384 soft nofile 60240 hard nofile 65536 hard core unlimited vim /etc/security/limits.d/90-nproc.conf soft nproc 50240root soft nproc unlimited vim /etc/sysctl.conf net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 60 net.ipv4.tcp_keepalive_time = 600net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000 net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_timestsmps = 0 net.ipv4.tcp_max_syn_backlog = 65536net.core.netdev_max_backlog = 32768net.core.somaxconn = 32768 net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_wmem = 8192 436600 873200net.ipv4.tcp_rmem = 32768 436600 873200net.ipv4.tcp_mem = 94500000 91500000 92700000net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_fin_timeout = 30 Liunx 最大文件数命令：ulimit -aopen files (-n) 1024“open files” 参数选项后面的数值就是当前系统的支持的最大打开文件数","categories":[],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://blog.shicc.top/tags/TCP-IP/"},{"name":"socket","slug":"socket","permalink":"http://blog.shicc.top/tags/socket/"},{"name":"liunx","slug":"liunx","permalink":"http://blog.shicc.top/tags/liunx/"}]},{"title":"Kafka LogStash ES","slug":"Kafka-Logstach-ES","date":"2018-06-26T03:52:05.000Z","updated":"2018-12-03T10:19:55.663Z","comments":true,"path":"Kafka-Logstach-ES.html","link":"","permalink":"http://blog.shicc.top/Kafka-Logstach-ES.html","excerpt":"","text":"Kafka LogStash ESjava 程序日志通过 logback，将日志写入kafka，在通过logstash采集kafka中数据，将数据写入ES中，最后通过 Kibana 查询程序日志。 中文编码问题： 程序日志中文写入 kafka，最后在Kibana中以Unicode的方式显示。 解决方法：1234567891011121314151617181920212223input &#123; kafka &#123; bootstrap_servers =&gt; &quot;kakfa ip&quot; group_id =&gt; &quot;Cosumer_10-127-28-11&quot; topics =&gt; &quot;logstash&quot; &lt;!-- codec =&gt; json_lines 修改中文显示方式 --&gt; codec =&gt; json_lines &#125;&#125;filter &#123;&#125;output &#123; elasticsearch&#123; action =&gt; &quot;index&quot; hosts =&gt; [&quot;es ip&quot;] user =&gt; &quot;elastic&quot; password =&gt; &quot;changeme&quot; index =&gt; &quot;applog&quot; &#125;&#125; pom.xml123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.danielwegener&lt;/groupId&gt; &lt;artifactId&gt;logback-kafka-appender&lt;/artifactId&gt; &lt;version&gt;0.2.0-RC1&lt;/version&gt;&lt;/dependency&gt; logback.xml123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--该日志将日志级别不同的log信息保存到不同的文件中 --&gt;&lt;configuration&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;/&gt; &lt;springProperty scope=&quot;context&quot; name=&quot;springAppName&quot; source=&quot;spring.application.name&quot;/&gt; &lt;springProperty scope=&quot;context&quot; name=&quot;springAppPort&quot; source=&quot;server.port&quot;/&gt; &lt;appender name=&quot;KafkaAppender&quot; class=&quot;com.github.danielwegener.logback.kafka.KafkaAppender&quot;&gt; &lt;encoder class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;&gt; &lt;includeContext&gt;true&lt;/includeContext&gt; &lt;includeCallerData&gt;true&lt;/includeCallerData&gt; &lt;customFields&gt;&#123;&quot;system&quot;:&quot;project-name&quot;&#125;&lt;/customFields&gt; &lt;fieldNames class=&quot;net.logstash.logback.fieldnames.ShortenedFieldNames&quot;/&gt; &lt;/encoder&gt; &lt;topic&gt;logstash&lt;/topic&gt; &lt;keyingStrategy class=&quot;com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy&quot;/&gt; &lt;deliveryStrategy class=&quot;com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy&quot;/&gt; &lt;producerConfig&gt;bootstrap.servers=&lt;/producerConfig&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=&quot;INFO&quot;&gt; &lt;appender-ref ref=&quot;KafkaAppender&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt;","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://blog.shicc.top/tags/Kafka/"},{"name":"LogStash","slug":"LogStash","permalink":"http://blog.shicc.top/tags/LogStash/"},{"name":"ES","slug":"ES","permalink":"http://blog.shicc.top/tags/ES/"}]},{"title":"Spring Cloud Config","slug":"Spring-Cloud-Config 详解","date":"2018-06-24T04:16:40.000Z","updated":"2018-12-03T10:19:55.669Z","comments":true,"path":"Spring-Cloud-Config 详解.html","link":"","permalink":"http://blog.shicc.top/Spring-Cloud-Config 详解.html","excerpt":"","text":"Spring Cloud Configapplication.yml 和 bootstrap.yml 区别加载顺序 bootstrap.yml 先加载 application.yml 后加载 bootstrap.yml 用于应用程序上下文的引导阶段。bootstrap.yml 由父 Spring ApplicationContext 加载。父ApplicationContext被加载到使用application.yml 的之前 配置区别bootstrap.yml 和 application.yml 都可以用来配置参数 bootstrap.yml 可以理解为系统级别的一些参数配置，这些参数一般是不会变动的。 application.yml 可以用来定义应用节级别的，如果搭配 spring-cloud-config 使用application.yml 里面定义的文件可以实现动态替换。使用Stpring Cloud Config Server时，应在bootstrap.yml 中指定： spring.application.name spring.cloud.config.server.git.url 一些加密/解密信息 application 的加载原理启动上下文Spring Cloud 会创建一个Bootstrap Context,作为Spring应用的Application Context的父上下文。初始化的时候，Bootstrap Context 复制从外部源加载配置属性并解析配置。 这两个上下文共享一个从外部获取的Environment.Bootstrap属性有高优先级，默认情况下，它们不会被本地配置覆盖。Bootstrap context 和 Application Context 有着不同的约定，所有新增了一个bootstrap.yml 文件，而不是使用application.yml。保证Bootstarp Context 和 Application Context 配置的分离。 应用上下文层次结构如果你通过 SpringApplicaion 或者 SpringApplicationBuilder创建一个Application Context,那么会为spring应用的Application Context 创建父上下文Bootstrap Context。在Spring里有个特性，子上下文会继承父类的property sources,会新增额外的property sources。额外的property sources 有： “bootstrap”： 如果在Boostrap Context 扫描到PropertySourceLocator并且有属性，则会添加到CompositePropertySource.Spring Cloud COnfig 就是通过这种方式来添加属性，详情请查看源码 ConfigServicePropertySourceLocator。 “applicationConfig:[classpath:bootstrap.yml]” (如果有 spring.profiles.active=production，则例如 applicationConfig:[classpath:/bootstrap.yml]#product): 如果你是用bootstrap.yml 来配置Bootstrap Context,他比application.yml 优先级别要低，它将添加到子上下文，作为Spring Boot 应用程序的一部分。 由于优先级规则，Bootstrap Context 不包含从Bootstrap.yml 来的数据，但可以用它作为默认设置。你可以很容易的扩展任何你建立的上下文层次，可以使用它提供的接口，或者使用 SpringApplicationBuillder包含的方法（parent(),child(),sibling()）。 Bootstrap Context 将是最高级别的父类。扩展的每一个Context都有自己的 bootstrap property source(有可能是空的)。扩展的每一个Context 都有不同 spring.application.name。 同一层层次的父子上下文原则上也有着不同的名称，因此，也会有不同的Config Server配置。子上下文的属性在相同名字的情况下将覆盖父上下文的属性。注意：SpringApplicationBuilder允许共享Environment到所有层次，但是不是默认的。 因此，同级的兄弟上下文不在和父类共享一些东西的时候不一定有相同的profiles或者property sources。 修改Bootstrap属性配置源码位置： BootstrapApplicationLister123456String configName = environment.resolvePlaceholders(&quot;$&#123;spring.cloud.bootstrap.name:bootstrap&#125;&quot;);String configLocation = environment.resolvePlaceholders(&quot;$&#123;spring.cloud.bootstrap.location:&#125;&quot;);Map&lt;String, Object&gt; bootstrapMap = new HashMap&lt;&gt;();bootstrapMap.put(&quot;spring.config.name&quot;,configName);if(StringUtils.hasText(configLocation))&#123; bootstrapMap.put(&quot;spring.config.location&quot;, configLocation);&#125; bootstrap.yml 是有spring.cloud.bootstrap.name(默认：“bootstrap”) 或者 spring.cloud.bootstrap.location(默认空)。这些属性行为与spring.config.* 类似，通过它的Environment来配置引导ApplicationContext。如果有一个激活的profile（来源与 spring.profiles.active 或者 Environment 的Api构建），例如 bootstrap-development.properies 就是配置了 profile为development的配置文件。 覆盖远程属性property sources 被bootstrap context添加到应用通常远程的方式，比如“Config Server”。默认情况下，本地的配置文件不能覆盖远程配置，但是可以通过启动命令参数来覆盖远程配置。如果需要本地文件覆盖远程文件，需要在远程配置文件里设置 spring.cloud.config.allowOverride=true（这个配置不能在本地被设置）。一旦设置了这个权限，你可以配置更加细粒度的配置来配置覆盖的方式。12spring.cloud.config.overrideNoe = true #覆盖任何本地属性spring.cloud.config.overrideSystemProperties=false #仅仅系统属性和环境变量 源文件详见 PropertySourceBootstrapProperties 自定义启动配置bootstrap context 是依赖 /META-INF/spring.factories 文件里面的 org.springframework.cloud.bootstrap.BootstrapConfiguration 条目下面，通过逗号分隔的Spring @Configuration 类来建立的配置。任何main application context 需要自动注入的Bean可以在这里通过这种方式获取。这也是 ApplicationContextInitializer 建立@Bean的方式。可以通过 @Order来更改初始化序列，默认是”last”。1234567891011121314151617181920# spring-cloud-context-1.1.1.RELEASE.jar# spring.factories# AutoConfigurationorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration,\\org.springframework.cloud.autoconfigure.RefreshAutoConfiguration,\\org.springframework.cloud.autoconfigure.RefreshEndpointAutoConfiguration,\\org.springframework.cloud.autoconfigure.LifecycleMvcEndpointAutoConfiguration# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.cloud.bootstrap.BootstrapApplicationListener,\\org.springframework.cloud.context.restart.RestartListener# Bootstrap componentsorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration,\\org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration,\\org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration,\\org.springframework.boot.autoconfigure.PropertyPlaceholderAutoConfiguration 你添加的自定义BootstrapConfiguration类没有错误的@ComponentScanned到你的主应用上下文，他们可能是不需要的。使用一个另外的包不被@ComponentScan或者@SpringBootApplication注解覆盖到。bootstrap context 通过 spring.factories 的配置类初始化所有的Bean都会在SpringApplication启动前加入到它的上下文里去。 自定义引导配置来源： Bootstrap Property Sources默认的property source 添加额外的配置是通过配置服务(Config Server),你也可以自定义添加 property soruce 通过实现 PropertySourceLocator 接口来添加。你可以使用它加配置属从不同的服务，数据库或者其他。demo：12345678@Configurationpublic class CustomPropertySourceLocator implements PropertySourceLocator &#123;@Overridepublic PropertySource&lt;?&gt; locate(Environment environment) &#123;return new MapPropertySource(&quot;customProperty&quot;, Collections.&lt;String, Object&gt;singletonMap(&quot;property.from.sample.custom.source&quot;, &quot;worked as intended&quot;));&#125;&#125; Environment 被 ApplicationContext建立，并传入 property sources(可能不同的profile有不同的属性)，所以，你可以从Environment寻找找一些特别的属性。比如spring.application.name,它是默认的Config Server property source。如果你建立了一个jar包，里面添加了一个 META-INF/spring.factories文件：org.springframework.cloud.bootstrap.BootstrapConfiguration=sample.custom.CustomPropertySourceLocator 。那么“CostomProperty” 的 参考资料(SpringCloud入门之常用的配置文件 application.yml和 bootstrap.yml区别)[https://www.cnblogs.com/BlogNetSpace/p/8469033.html] (Spring Boot)[https://docs.spring.io/spring-boot/docs/2.0.3.RELEASE/reference/htmlsingle/] (Spring Boot)[https://github.com/spring-projects/spring-boot]","categories":[],"tags":[{"name":"Spring Cloud Config","slug":"Spring-Cloud-Config","permalink":"http://blog.shicc.top/tags/Spring-Cloud-Config/"}]},{"title":"Spring Cloud 中间组件","slug":"Spring Cloud 中间组件","date":"2018-06-22T03:48:40.000Z","updated":"2018-12-03T10:19:55.668Z","comments":true,"path":"Spring Cloud 中间组件.html","link":"","permalink":"http://blog.shicc.top/Spring Cloud 中间组件.html","excerpt":"","text":"","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"}]},{"title":"spring 技术内幕学习笔记","slug":"spring 技术内幕","date":"2018-05-24T03:48:40.000Z","updated":"2018-12-03T10:19:55.675Z","comments":true,"path":"spring 技术内幕.html","link":"","permalink":"http://blog.shicc.top/spring 技术内幕.html","excerpt":"","text":"Spring Aop： Spring 集成了AspectJ做为Aop的一个特定实现，同时还在JVM动态代理/CGLIB的基础上，实现了一个AOP框架，作为Spring集成到其他模块的工具，比如 TranscationProxyFactoryBean 声明式事务处理，就是通过AOP集成到Spring中的。在这个模块中，Spring AOP 实现了一个完整的建立AOP代理对象，实现AOP拦截器，直至实现各种Advice通知的过程。","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://blog.shicc.top/tags/ElasticSearch/"}]},{"title":"Spring CacheManager","slug":"Spring CacheManager","date":"2018-04-11T13:01:05.000Z","updated":"2018-12-03T10:19:55.666Z","comments":true,"path":"Spring CacheManager.html","link":"","permalink":"http://blog.shicc.top/Spring CacheManager.html","excerpt":"","text":"Spring 中提供了很多存储器，例如： SimpleCacheManager , EhCacheCacheManager, GuavaCacheManager, CompositeCacheManger。处理核心的Spring框架之外，Spring Date 提供提供了Redis缓存管理器。RedisCacheManager。 Spring Boot 中通过 @EnableCaching 注解自动化配置合适的缓存管理器。默认情况下Spring Boot 根据以下顺序自动检测缓存提供者： Generic JCache (JSR-107) EhCache 2.x Hazelcast Infinispan Redis Guava Simple 若我们手动配置RedisTemplate后，Spring Boot 就无法自动给RedisCacheManager设置redisTemplate，所以需要自己配置RedisCacheManager。 123456789101112131415161718192021222324252627282930313233RedisConfig.java@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport &#123; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;String, String&gt;(); redisTemplate.setConnectionFactory(factory); redisTemplate.afterPropertiesSet(); setSerializer(redisTemplate); return redisTemplate; &#125; private void setSerializer(RedisTemplate&lt;String, String&gt; template) &#123; Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(jackson2JsonRedisSerializer); &#125; @Bean public CacheManager cacheManager(RedisTemplate redisTemplate) &#123; RedisCacheManager rcm = new RedisCacheManager(redisTemplate); // 设置缓存过期时间，秒 rcm.setDefaultExpiration(60); return rcm; &#125;&#125; Spring 提供了以下注解来声明缓存规则 @Cacheable triggers cache population 表明Spring在调用方法之前，首先应该在缓存中查找方法的返回值，，如果这个值能够找到，就会返回这个值。否则的话，这个方法就会被调用，返回值会放到缓存中@CacheEvict triggers cache eviction 表明Spring应该在缓存中清除一个或多个条目@CachePut updates the cache without interfering 表明Spring应该将方法的返回值放到缓存中，在方法的调用前并不会检查，方法始终都会被调用@Caching regroups multiple cache operations to be applied on a method@CacheConfig shares some common cache-related setting at class-level 可以在类层级配置一些公用的缓存配置 @Cacheable 和 @CachePut 共有属性： 属性 类型 描述 value String[] 要使用的缓存名称 condition String SpEL 表达式，如果得到的值是false的话，不会将缓存应用到方法调用上 key String SpEL表达式，用来计算自定义的缓存key unless String SpEL表达式，如果得到的值是true的话，返回值不会放到缓存之中 使用 CacheManager 的有点：CacheManager 是所有缓存管理器的父级，定义了一些通用接口。具体的缓存实现可以继承CacheManger，并自行实现功能。通过这个方法可以进行拆分解耦，当替换其他缓存插件时，不需要修改代码，只需要修改配置文件就行。 Redis 在项目中的使用 开启Redis事务 @Transactional 与 stringRedisTemplate.setEnableTransactionSupport(true); 需要同时启用。 查询不存在的数据，需要将一组空数据写入Redis，防止数据库被穿透。 查询数据时，需要使用 lock ，来防止所有请求都走数据库，而不走Redis，大流量，大并发的情况下。 Redis 集群Redis 集群只有 db0，不支持 select db操作，不支持 Redis 事务操作。","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shicc.top/tags/Spring/"},{"name":"CacheManager - Redis","slug":"CacheManager-Redis","permalink":"http://blog.shicc.top/tags/CacheManager-Redis/"}]},{"title":"代码分析","slug":"代码分析","date":"2018-04-06T11:03:49.000Z","updated":"2018-12-03T10:19:55.677Z","comments":true,"path":"代码分析.html","link":"","permalink":"http://blog.shicc.top/代码分析.html","excerpt":"","text":"命名方法 定义变量名字，使用 名词而非东西 基于Rest 风格，使用 名词复数 + Http动词定义url，实现功能 编码标准 checkStyle 阿里编码标准 代码重复（PMD的CPD的使用）测试代码覆盖率（Eclemma）依赖项分析（JDepend的使用）复杂度分析（Metrics的使用）参考资料 追求代码质量：软件架构的代码质量 JDepend PMD CheckStyle Eclemma Metrics","categories":[],"tags":[{"name":"代码分析","slug":"代码分析","permalink":"http://blog.shicc.top/tags/代码分析/"}]},{"title":"ElasticSearch入门教程","slug":"ElasticSearch入门教程","date":"2018-03-24T03:48:40.000Z","updated":"2019-01-24T09:41:52.988Z","comments":true,"path":"ElasticSearch入门教程.html","link":"","permalink":"http://blog.shicc.top/ElasticSearch入门教程.html","excerpt":"","text":"ElasticSearch入门教程ES 基本概念Cluster: 集群Node: 节点Shard: 分片Replia: 副本全文检索 MySQL ElasticSearch Database Index Table Type Row Document Column Field Schema Mapping Index Everything is indexed SQL Query DSL SELECT * FROM table GET UPDATE table SET PUT ELKELK = ElasticSearch + Logstash + Kibana ES特点和优势 分布式实时文件存储，可将每一个字段存入索引，使其可以被检索到 实时分析的分布式搜索引擎 分布式：索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作。 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据 支持插件机制，分词插件，同步插件，Hadoop 插件，可视化插件。 Linux 下安装ElasticSearch 下载 ElasticSearch 安装 ElasticSearch 1tar -zxvf elasticsearch-2.3.3.tar.gz 启动 1./elasticsearch 查看信息1curl -X GET &apos;http://localhost:9200&apos; elasticsearch 外网访问 123# 修改配置文件 config/elasticsearch.ymlnetwork.host: 0.0.0.0 安装注意点 ElasticSearch 不能使用root帐号启动 服务器 /etc/sysctl.conf 配置信息 vm.max_map_count = 655360 ,重启命令 sysctl -p 服务器ulimit -a 查看文件数，配置文件位置/etc/security/limits.conf,修改之后退出当前用户，或者重新登录。1[1]: max number of threads [1024] for user [sgm] is too low, increase to at least [4096] ###下载安装插件 安装分词插件 1./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v5.5.1/elasticsearch-analysis-ik-5.5.1.zip 1./plugin install mobz/elasticsearch-head 基本概念Node 与 ClusterElastic本质是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个Elastic实例。 单个Elastic实例称为一个节点(node).一组节点构成一个集群(cluster)。 IndexElastic会索引所有字段，经过处理后写入一个反向索引(Inverted Index)。查找数据的时候，直接查找该索引。 Elastic数据管理的顶层单位就叫做Index(索引)。它是单个数据库的同义词。每个Index(即数据库)的名字必须是小写。 查看当前节点的所有Index1curl -X GET &apos;uri/_cat/indices?v&apos; DocumentIndex 里面单条的记录称为Docuemnt(文档)。许多条Document构成一个Index。 同一个Index里面的Document不要求相同的结构(scheme)，但是最好能保持相同，这样有利于提高搜索效率。 TypeDocument 可以分组，比如 weather 这个Index里面，可以按城市分组(北京和上海)，也可以按气候分组(晴天和雨天)。这种分组就叫做Type，它是虚拟的逻辑分组，用来过滤Document。 不同的Type应该有相似的结构(Schema),举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据(比如products 和 logs)应该存成两个Index，而不是一个Index里面的两个Type 列出每个Index所包含的Type1localhost:9200/_mapping?pretty=true Tip:Elastic 6.x 版只允许每个Index包含一个Type，7.x 版将会彻底移除Type。 新建和删除Index新建Index，可以直接想Elastic服务器发出PUT请求。新建一个名叫weather的Index1curl -X PUT &apos;localhost:9200/weather&apos; 发出 Delete 请求删除这个Index1curl -X DELETE &apos;localhost:9200/weather&apos; 中文分词凡是需要搜索的中文字段，都需要单独设置12345678910111213141516171819202122232425curl -X PUT &apos;url&apos; -d &apos;&#123; &quot;mappings&quot;:&#123; &quot;person&quot;:&#123; &quot;properties&quot;: &#123; &quot;user&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;desc&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_max_word&quot; &#125; &#125; &#125; &#125;&#125;&apos; 上面代码中, analyzer是字段文本的分词器，search_analyzer是搜索词的分词器。ik_max_word分词器是插件ik提供的，可以对文本进行最大数量的分词。 数据操作向指定的 /Index/Type 发送PUT请求，就可以在Index里面新增一条记录。例如：1234567curl -X PUT &apos;localhost:9200/accounts/persion/1&apos; -d &apos;&#123; &quot;user&quot;: &quot;张三&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;数据库管理&quot;&#125;&apos; 服务器返回的JSON对象，会给出Index，Type，Id，Version等信息。12345678910111213&#123; &quot;_index&quot;: &quot;accounts&quot;, &quot;_type&quot;: &quot;person&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: &quot;1&quot;, &quot;result&quot;: &quot;create&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;created&quot;: true&#125; 上代码插入的请求路径是/accounts/person/1,最后的 1是改条记录的Id。它不一定是数字，任意字符串(比如 abc) 都可以。 新增记录的时候，也可以不指定Id，这时要改成POST 请求。1234567curl -X POST &apos;localhost:9200/accounts/person&apos; -d &apos;&#123; &quot;user&quot;: &quot;李四&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;系统管理&quot;&#125;&apos; 通过POST发出一个请求，添加一条记录，这时服务器返回的JSON对象里面，_id 字段就是一个随机字符串。 查看记录向 /Index/Type/Id 发出GET请求，就可以查看这条记录。1curl &apos;localhost:9200&apos;/accounts/person/1?pretty=true&apos; 请求查看/accounts/persopn/1这条记录，URL的参数 pretty=true表示以易读的格式返回。返回的数据中,found字段表示查询成功,_source字段返回原始记录。123456789101112&#123; &quot;_index&quot;: &quot;accounts&quot;, &quot;_type&quot;: &quot;person&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 1, &quot;found&quot;: true, &quot;_source&quot;:&#123; &quot;user&quot;:&quot;&quot;, &quot;title&quot;: &quot;&quot;, &quot;desc&quot;: &quot;&quot; &#125;&#125; 如果Id不正确，就查不到数据，found字段就是false 删除记录删除记录就是发出DELETE请求1curl -X DELETE &apos;localhost:9200/accounts/person/1&apos; 更新数据更新记录就是使用PUT请求，重新发送一次数据。12345curl -X PUT &apos;localhost:9200/accounts/person/1&apos; -d &apos;&#123; &quot;user&quot;: &quot;张三&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;数据库管理，软件开发&quot;&#125;&apos; 返回信息123456789&#123; &quot;_index&quot;: &quot;accounts&quot;, &quot;_type&quot;: &quot;person&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_version&quot;: 2, &quot;result&quot;: &quot;updated&quot;, &quot;_shards&quot;: &#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;, &quot;created&quot;: false&#125; 从上面的记录可以看到，记录的Id没变，但是版本(version)从1变成了2，操作类型(result)从created变成updated,created字段变成false,因为这次不是新建记录。 数据查询返回所有记录使用GET方法，直接请求/Index/Type/_search,就会返回所有记录。123456789101112131415161718192021222324curl &apos;localhost:9200/accounts/person/_search&apos;&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;, &quot;hits&quot;:&#123; &quot;total&quot;:2, &quot;max_score&quot;: 1.0, &quot;hits&quot;:&#123; &#123; &quot;_index&quot;: &quot;accounts&quot;, &quot;_type&quot;: &quot;person&quot;, &quot;_id&quot;: &quot;xxxx&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: &#123; &quot;user&quot;:&quot;&quot;, &quot;title&quot;:&quot;&quot;, &quot;desc&quot;: &quot;&quot; &#125; &#125; &#125; &#125;&#125; 上面代码中，返回结果的took字段表示改操作的耗时(单位是毫秒),timed_out字段表示是否超时，hits字段表示命中的记录，里面子字段的含义如下123total 返回记录数max_score 最高的匹配程度hits 返回的记录组成的数组 返回的记录中，每条记录都有一个_score字段，表示匹配的程序，默认是按照这个字段降序排列。 全文搜索Elastic的查询非常特别，使用自己的查询语法,要求GET请求带有数据体。12345curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;desc&quot;: &quot;软件&quot;&#125;&#125;&#125;&apos; 上面代码使用Match 查询,指定的匹配条件是desc字段里面包含”软件”这个词。返回结果如下：123456789101112&#123; &quot;took&quot;: 3, &quot;time_out&quot;: false, &quot;_shards&quot;: &#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;, &quot;hits&quot;:&#123; &quot;total&quot;: 1, &quot;max_score&quot;: &quot;0.2858&quot;, &quot;hits&quot;:[ &#123;&#125; ] &#125;&#125; Elastic默认一次返回10条结果，可以通过size字段改变这个设置。123456curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;desc&quot;:&quot;管理&quot;&#125;&#125;, &quot;size&quot;: 1&#125;&apos; 上面的代码指定，每次只返回一条结果。 还可以通过from字段，指定位移。12345curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot;: &#123;&quot;match&quot;: &#123;&quot;desc&quot;:&quot;管理&quot;&#125;&#125;, &quot;from&quot;: 1, &quot;size&quot;: 1&#125;&apos; 上面代码指定，从位置1开始(默认是从位置0开始)，只返回一条结果。 逻辑运算如果有多个搜索关键字，Elastic认为它们是or关系。12345curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot;:&#123;&quot;match&quot;: &#123;&quot;desc&quot;: &quot;系统 软件&quot;&#125;&#125;&#125;&apos; 上面的代码搜索的是软件 or 系统。如果要执行多个关键字词的and搜索，必须使用布尔查询。123456789101112curl &apos;localhost:9200/accounts/person/_search&apos; -d &apos;&#123; &quot;query&quot;: &#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123;&quot;match&quot;: &#123;&quot;desc&quot;: &quot;软件&quot;&#125;&#125;, &#123;&quot;match&quot;: &#123;&quot;desc&quot;: &quot;系统&quot;&#125;&#125; ] &#125; &#125;&#125;&apos; REST APIES 学习ES 学习 ES 在Java 中的使用","categories":[],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://blog.shicc.top/tags/ElasticSearch/"}]},{"title":"Spring RestTemplate 乱码问题","slug":"Spring-RestTemplate","date":"2018-03-24T03:48:40.000Z","updated":"2018-12-03T10:19:55.669Z","comments":true,"path":"Spring-RestTemplate.html","link":"","permalink":"http://blog.shicc.top/Spring-RestTemplate.html","excerpt":"","text":"自行创建一个 RestTemplate Bean,并在Bean中设置编码格式。","categories":[],"tags":[{"name":"RestTemplate 乱码问题","slug":"RestTemplate-乱码问题","permalink":"http://blog.shicc.top/tags/RestTemplate-乱码问题/"}]},{"title":"Freemarker 入门知识","slug":"Freemarker","date":"2017-12-17T01:22:05.000Z","updated":"2018-12-03T10:19:55.660Z","comments":true,"path":"Freemarker.html","link":"","permalink":"http://blog.shicc.top/Freemarker.html","excerpt":"","text":"Freemarker 入门知识Configuration 三种模版加载方式 void setDirectoryForTemplateLoading(File file); void setClassForTemplateLoading(Class cl,String prefix); void setServletContextForTemplateLoading(Object servletContext,String path); 核心代码1234Template template = config.getTemplate(&quot;test.ftl&quot;, &quot;utf-8&quot;);Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();map.put(&quot;name&quot;, &quot;shicc&quot;);template.process(map, out); 构建一个 Template 对象，执行template.process() 进行处理，最后解析 Writer 获取执行完成的字符串。","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"http://blog.shicc.top/tags/centos/"},{"name":"64位aapt","slug":"64位aapt","permalink":"http://blog.shicc.top/tags/64位aapt/"},{"name":"aapt","slug":"aapt","permalink":"http://blog.shicc.top/tags/aapt/"},{"name":"apk","slug":"apk","permalink":"http://blog.shicc.top/tags/apk/"}]},{"title":"CentOS 6.5 安装 64位 aapt","slug":"aapt","date":"2017-12-17T01:22:05.000Z","updated":"2018-12-03T10:19:55.670Z","comments":true,"path":"aapt.html","link":"","permalink":"http://blog.shicc.top/aapt.html","excerpt":"","text":"CentOS 6.5 安装 64位 aapt通过 aapt 解析 apk包，获取包信息，版本信息等。 aapt在windows、linux、mac分别有对应的文件，我们可以通过解压apktool.jar获取。 aapt文件有32位和64位之分。在 64位操作系统中安装32位的aapt需要安装glibc.i686、zlib.i686、libstdc，但是官方又没提供64位的aapt文件。我们可以自己在64位操作系统编译。已经编译好的64位aapt文件 aapt_64。 把64位aapt文件上传到服务器后，chmod +x aapt添加运行权限，执行./aapt后会发现报libc.so.6: version ‘GLIBC_2.14’ not found，下面需要我们安装glibc2.14。 下载glibc-2.14.tar.xz上传到服务器 运行tar -xvf glibc-2.14.tar.xz解压。 解压完成后，我们进入glibc-2.14目录：cd glibc-2.14。 创建glibc源码构建目录：mkdir build，然后进入build目录：cd build。在build目录我们运行../configure –prefix=/opt/glibc-2.14进行配置，然后运行make -j4进行编译，最后运行sudo make install进行安装。 运行strings /lib64/libc.so.6 |grep GLIBC_ 发现还是没有2.14版本 cp -r /etc/ld.so.c* /opt/glibc-2.14/etc/ ln -sf /opt/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 再运行strings /lib64/libc.so.6 |grep GLIBC_可以从结果中找到GLIBC_2.14版本 运行./aapt出现Android Asset Packaging Tool…信息证明配置成功。","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"http://blog.shicc.top/tags/centos/"},{"name":"64位aapt","slug":"64位aapt","permalink":"http://blog.shicc.top/tags/64位aapt/"},{"name":"aapt","slug":"aapt","permalink":"http://blog.shicc.top/tags/aapt/"},{"name":"apk","slug":"apk","permalink":"http://blog.shicc.top/tags/apk/"}]},{"title":"vue 入门重点","slug":"vue-start","date":"2017-11-23T01:22:05.000Z","updated":"2018-12-03T10:19:55.676Z","comments":true,"path":"vue-start.html","link":"","permalink":"http://blog.shicc.top/vue-start.html","excerpt":"","text":"vue 参数： data props 依赖父子通信 methods 方法 computed 计算，与methods 的区别，computed带有缓存功能 watch 监控data中的数据 directives 自定义指令 特殊变量$set vm.$set 实例方法，它只是全局 Vue.set 的别名。 $event 在内联语句处理器中访问原始的 DOM 事件 事件修饰符 .stop .prevent .capture .self .once使用修饰符时，顺序很重要；相应的代码会以相同的顺序产生。因此，用`@click.prevent.self会阻止所有的点击，而@check.self.prevent`只会阻止对元素自身的点击。 按键修饰符keyup.enter 回车事件 定义全局自定义按键修饰别名Vue.config.keyCodes.f1 = 112 组件组合DOM 模版解析注意事项把Vue实例挂载到一个已有内容的元素上，会受到 html 本身的一些限制，因为vue只有在浏览器解析、规范化模版之后才能获取其内容。尤其要注意 &lt;ul&gt; &lt;ol&gt; &lt;table&gt; &lt;select&gt; 这样的元素只能出现在某些特定元素的内部。解决方法： 使用特殊的 is 特性。 字符串模版 &lt;script type=&quot;text/x-template&quot;&gt;&lt;/script&gt; JavaScript 内联模版字符串 .vue 组件 父子组件： 组件A在它的模版中使用了组件B，它们之间必然需要相互通信。父组件可能要给子组件下发数据，子组件则可能要将它内部发生的事件告知父组件。父子组件的关系可以总结为 prop向下传递，事件向上传递。父组件通过 prop 给子组件下发数据，子组件通过事件给父组件发送消息。 camelCase vs. kebab-caseHTML 特性是不区分大小写，所以当使用的不是字符串模版时，camelCase(驼峰式命名)的prop需要转换为相对应的 kebab-case(短横线分隔式命名) 动态Prop使用 v-bind 来动态地将prop绑定到父组件的数据。每当父组件的数据变化时，该变化也会传给子组件：12345678&lt;div&gt; &lt;input v-model=&quot;parentMsg&quot;&gt; &lt;br&gt; &lt;child v-bind:my-message=&quot;parentMsg&quot;&gt;&lt;/child&gt;&lt;/div&gt;--- 缩写方式&lt;child :my-message=&quot;parentMsg&quot;&gt;&lt;/child&gt; Prop 验证要指定验证规则，需要用对象的形式来定义 prop ，而不能用字符串数组。 自定义事件使用v-on绑定自定义事件 使用$on(eventName) 监听事件 使用$emit(eventName) 触发事件父组件可以在使用子组件的地方直接使用v-on 来监听子组件触发的事件。 事件修饰符 给组件绑定原生事件使用v-on的修饰符.native。 1&lt;my-component v-on:click.native=&quot;doTheThing&quot;&gt;&lt;/my-component&gt; .sync 修饰符.sync 对一个prop进行双向绑定。 指令中钩子函数 bind 只调用一次，指令第一次绑定到元素时调用。在这里可以进行一次性的初始化设置 inserted 被绑定元素插入父节点调用（仅保证父节点存在，但不一定已被插入文档） update 所有组件的VNode更新时调用，但是可能发生其子VNode更新之前。指令的值可能发生了改变，也可能没有。 componentUpdated 指令所在组件的VNode及其子VNode全部更新后调用 unbind 只调用一次，指令与元素解绑时调用 vm对象vm 是 vue 的一个实例。vm获取其他属性：12el = vm.$eldata = vm.$data 状态管理（VUEX）store中state的改变都放置在store自身的action中去管理。这种集中式状态管理能够被更容易地理解哪种类型的 mutation 将会发生，以及它们是如何被触发。 主要参数 state 定义变量 getter 提供一些方法获取变量值 mutation 修改store 中的状态，并通过commit(‘method’)触发对象风格的提交方式 store.commit({type:”method”,amount:10}) 同步事务 action 处理异步操作，修改store中的状态，并通过commit(‘method’) module plugins Getter对vuex中 state 数据封装一些公共方法方便使用。12345getters:&#123; doneTodos:function(state,getter)&#123; &#125;&#125; Getter 也可以接受其他 getter 作为第二个参数使用方法1store.getters.methodName Mutation更改vuex的store中的状态的唯一方法是提交 mutation 。 vuex 中的mutation非常类似于事件。每个 mutation 都有一个字符类型的事件类型（type）和一个回调函数（handler）。回调函数就是我们实际进行状态更改的地方，并且它会接受一个 state 作为第一个参数。向 store.commit 传入的额外的参数，即 mutation 的载荷（payload） 对象风格的提交方式1234store.commit(&#123; type: &apos;increment&apos;, amount: 10&#125;) mutation 必须是同步函数Action Action 提交的是 mutation，而不是直接变更状态。 Action 可以包含任意异步操作。Action 通过 store.dispatch 方法触发：1store.dispatch(&apos;increment&apos;) 组合Actionaction 返回的 promises 是异步对象，使用 then 等待异步函数执行完成，并进行下一步操作。 Module将 store 分割成模块（module）,每个模块拥有自己的 state mutation action getter 甚至是嵌套子模块–从上至下进行同样方式的分割。 对于模块中的局部方法，根节点状态会作为第三个参数暴露出来。 vuex 辅助函数mapGettersimport {mapGetters} form ‘vuex’ getters 辅助函数 mapGettersmapGetters辅助函数仅仅将store中的getters映射到局部 computed 属性。 mutation 辅助函数 mapMutationsmapMutations 辅助函数将组件中的methods映射为 store.commit 调用1234567891011export default &#123; methods: &#123; ...mapMutations([ &apos;increment&apos;, &apos;incrementBy&apos; ]), ...mapMutations(&#123; add:&apos;increment&apos; //将 this.add() 映射到 this.$store.commit(&apos;increment&apos;) &#125;) &#125;&#125; action 辅助函数 mapActions网站 ECMAScript 6 入门 vue vuex vue-router axios axios 中文文档 翻译","categories":[],"tags":[{"name":"vue","slug":"vue","permalink":"http://blog.shicc.top/tags/vue/"}]},{"title":"Java类的加载机制","slug":"Java类的加载机制","date":"2017-10-20T02:33:24.000Z","updated":"2018-12-03T10:19:55.661Z","comments":true,"path":"Java类的加载机制.html","link":"","permalink":"http://blog.shicc.top/Java类的加载机制.html","excerpt":"","text":"什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 类的生命周期 其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 https://www.cnblogs.com/leeSmall/p/7517356.html","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://blog.shicc.top/tags/JVM/"}]},{"title":"理解 zookeeper","slug":"zookeeper","date":"2017-10-20T02:33:24.000Z","updated":"2018-12-03T10:19:55.677Z","comments":true,"path":"zookeeper.html","link":"","permalink":"http://blog.shicc.top/zookeeper.html","excerpt":"","text":"理解 zookeeperZookeeper 主要用来解决分布式应用中经常遇到的一些数据管理，如统一命名服务器、状态同步服务、集群管理、分布式应用配置项的管理。 节点特性 同一时刻多台机器创建同一个节点，只有一个会争抢成功。利用这个特性可以做分布式锁。 临时节点的生命周期与会话一致，会话关闭则临时节点删除。利用这个特性经常来做心跳，动态监控，负载等动作。 顺序节点保证节点名全局唯一。这个特性可以用来生成分布式环境下的全局自增长id。 zookeeper 提供的服务 创建节点 删除节点 更新节点 获取节点信息 权限控制 事件监听 Zookeeper的集群对server进行了归类： Leader Follower Observer Zookeeper 作用（使用场景） 配置中心 – Zookeeper 的目录结构比较特殊，可以这个特性作为分布式的配置中心，当配置内容发生更新可以及时通知各服务器进行更新 集群选举 – 当某一个服务宕机或者整个服务重启，可根据Zookeeper节点的顺序一致性来选择最大节点或者最小节点作为leader 分布式锁 – 原理同集群选举，根据节点的顺序一致性来选择最小节点对应的那个服务获得锁，当服务执行完成删除节点就会释放锁，再由其他服务去争取锁。 注册中心 – Zookeeper的目录以及子节点。主要通过对节点的管理做到发布以及事件监听做到订阅。 队列管理 同步队列 当一个队列的队员都聚气时，队列才可用，否则一直等待所有的成员到达，这种是同步队列 创建一个父目录 /synchronizing ，每个成员都监控标志(Set Watch)位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 、synchronizing 目录的所有目录节点，也就是 member_i,判断 i 的值是否已经是成员的目录，如果小于成员个数就等待 synchronizing/start 的出现，如果相等就创建synchronizing/start 异步队列 队列按照FIFO方式进行入队和出队操作，例如实现生产者和消费者模型。 保证所有成员加入队列时都是有编号的，出队是通过getChildren() 方法可以返回当前所有的队列元素，然后消费其中最小的元素。 Zookeeper 在分布式中的作用：使用Zookeeper提供分布式锁机制，从而实现分布式的一致性处理。 Barrier Queue Lock 2PC Java Api 接口12345678910111213141516171819202122232425262728293031String create(String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode)void create(String path, byte data[], List&lt;ACL&gt; acl, CreateMode createMode, StringCallback cb, Object ctx)void delete(String path, int version)void delete(String path, int version, VoidCallback cb, Object ctx)Stat setData(String path, byte data[], int version)void setData(String path, byte data[], int version, StatCallback cb, Object ctx)Stat setACL(String path, List&lt;ACL&gt; acl, int version)void setACL(String path, List&lt;ACL&gt; acl, int version, StatCallback cb, Object ctx)Stat exists(String path, Watcher watcher)Stat exists(String path, boolean watch)void exists(String path, Watcher watcher, StatCallback cb, Object ctx)void exists(String path, boolean watch , StatCallback cb, Object ctx)byte[] getData(String path, Watcher watcher, Stat stat)byte[] getData(String path, boolean watch , Stat stat)void getData(String path, Watcher watcher, DataCallback cb, Object ctx)void getData(String path, boolean watch , DataCallback cb, Object ctx)List&lt;String&gt; getChildren(String path, Watcher watcher)List&lt;String&gt; getChildren(String path, boolean watch )void getChildren(String path, Watcher watcher, ChildrenCallback cb, Object ctx)void getChildren(String path, boolean watch , ChildrenCallback cb, Object ctx)List&lt;String&gt; getChildren(String path, Watcher watcher, Stat stat)List&lt;String&gt; getChildren(String path, boolean watch , Stat stat)void getChildren(String path, Watcher watcher, Children2Callback cb, Object ctx)void getChildren(String path, boolean watch , Children2Callback cb, Object ctx) 接口说明 每一种安同步还是异步 添加指定watcher还是默认watcher分为4中。默认watcher在Zookeeper 初始化中进行指定。 如果包含boolean watch 的读方法传入true，则将默认为watcher注册为所关注事件的watch。如果传入false则不注册watch。 CreateMode PERSISTENT 持续的。相比与EPHEMERAL，不会随着client session的close或者expire而消失 PERSISTENT_SEQUENTIAL EPHEMERAL 短暂的，生命周期依赖于client session、对应session close/expire 后其znode也会消失。 EPHEMERAL_SEQUENTIAL SEQUENTIAL意为顺序的。 Zookeeper 为了解决数据的一致性，使用Watcher的异步回调接口，将服务器znode的变化以事件的形式通知给客户端，主要是一种方向推送的机制，让客户端可以做出及时响应。比如及时更新后端的可用集群服务列表。 参考网站Zookeeper Api(java)入门与应用(转) 保证分布式系统数据一致性的6种方案 解决分布式系统的一致性问题，我们需要了解哪些理论 分布式系统的事务处理 ZooKeeper典型应用场景一览 zookeeper中的基本概念 Watcher/Callback 参考网站http://luzengyi.blog.163.com/blog/static/529188201064113744373/http://luzengyi.blog.163.com/blog/static/529188201061155444869/ ACLhttp://rdc.taobao.com/team/jm/archives/947 集群管理paxos 实现paxos算法介绍续zookeeper代码解析 Zookeeper 官方文档http://zookeeper.apache.org/doc/r3.3.2/recipes.html TODOZookeeper 一致性","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://blog.shicc.top/tags/zookeeper/"},{"name":"zookeeper的使用情景","slug":"zookeeper的使用情景","permalink":"http://blog.shicc.top/tags/zookeeper的使用情景/"},{"name":"zookeeper的作用","slug":"zookeeper的作用","permalink":"http://blog.shicc.top/tags/zookeeper的作用/"}]},{"title":"Redis 常用操作","slug":"Redis 常用操作","date":"2017-10-10T01:22:05.000Z","updated":"2018-12-03T10:19:55.664Z","comments":true,"path":"Redis 常用操作.html","link":"","permalink":"http://blog.shicc.top/Redis 常用操作.html","excerpt":"","text":"","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.shicc.top/tags/Redis/"}]},{"title":"性能分析之iostat","slug":"iostat","date":"2017-10-10T01:22:05.000Z","updated":"2018-12-03T10:19:55.671Z","comments":true,"path":"iostat.html","link":"","permalink":"http://blog.shicc.top/iostat.html","excerpt":"","text":"iostatiostat 主要用于监控系统设备的IO负载情况，iostat首次运行时系统启动开始的各项统计信息，之后运行iostat将会显示自上次运行该命令以后的统计信息。用于通过指定统计的次数和时间来获取所需的统计信息。 命令模式1iostat [ -c | -d ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ device [ ... ] | ALL ] [ -p [ device | ALL ] ] [ interval [ count ] ] 参数说明1234567891011-c 仅显示CPU统计信息.与-d选项互斥.-d 仅显示磁盘统计信息.与-c选项互斥.-k 以K为单位显示每秒的磁盘请求数,默认单位块.-p device | ALL 与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如: # iostat -p hda 或显示所有设备 # iostat -p ALL-t 在输出数据时,打印搜集数据的时间.-V 打印版本号和帮助信息.-x 输出扩展信息. 入门12iostat -d -k 2 10iostat -d -k interval [count] 参数说明 -d 表示设备(磁盘)使用状态； -k 某些使用block为单位的列强制使用Kilobytes为单位 2[interval] 表示每隔2秒刷新一次 10[count] 表示总共输出10次 -x 用于显示和io相关的扩展数据 -c 用来获取cpu部分状态值 输出信息的意义 tps 该设备每秒传输的次数。“一次传输”意思是“一次IO请求”。多个逻辑请求可能会被合并为”一次IO请求”。“一次传输”请求的大小是未知的。 kB_read/s 每秒从设备读取的数据量 kB_wrtn/s 每秒想设备写入的数据量 kB_read 读取的总数据量 kB_wrtn 写入总数据量 -x 输出信息的含义 rrqm/s 每秒这个设备相同的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS,如果FS发现不同的读取请求读取的是相同Block的数据，FS就会将这个请求合并Merge） wrqm/s 每秒这个设备相关的写入请求有多少被Merge了 rsec/s 每秒读取的扇区数 wsec/s 每秒写入的扇区数 rKB/s the number of read requests that were issued to device per second wKB/s the number of write requests that were issued to device per second avgrq-sz 请求扇区大小 avgqu-sz 是平均请求队列的长度。好无疑问，队列长度越短越好 await 每个IO请求的处理的平均时间(单位是毫秒)。这个可以理解为IO的相应时间，一般地系统IO时间应该低于5ms，如果大于10ms就比较大了。这个时间包括队列时间和服务时间，也就是说一般情况下 await大于svctm，他们的差值越小说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。 svctm 表示平均每次设备IO操作的服务器时间（以毫秒为单位）。如果 svctm的值和await很接近，表示几乎没有IO等待，磁盘性能很好，如果await的值远高于svctm的值，则表示IO队列等待太长，系统运行的应用程序将会变慢。 %util 在统计时间内所有IO时间，除以总共统计时间。例如统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%, 所以该参数暗示了设备的繁忙程度。一般地，如果该参数的100%表示该设备已经接近满负荷运行了。（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈） 常见用法iostat -x 1 20iostat -d -k 1 10 查看TPS和吞吐量信息（磁盘读写速度单位为KB）iostat -d -m 2 查看TPShe吞吐量信息（磁盘读写速度单位为MB）iostat -d -x -k 1 10 查看设备使用率(%util),响应时间(await)iostat -c 1 10 查看cpu状态 实例分析12345678ostat -d -k 1 |grep sda10Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda10 60.72 18.95 71.53 395637647 1493241908sda10 299.02 4266.67 129.41 4352 132sda10 483.84 4589.90 4117.17 4544 4076sda10 218.00 3360.00 100.00 3360 100sda10 546.00 8784.00 124.00 8784 124sda10 827.00 13232.00 136.00 13232 136 磁盘每秒传输次数平均约400；每秒磁盘读取约5MB,写入约1MB。 12345iostat -d -x -k 1Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 1.56 28.31 7.84 31.50 43.65 3.16 21.82 1.58 1.19 0.03 0.80 2.61 10.29sda 1.98 24.75 419.80 6.93 13465.35 253.47 6732.67 126.73 32.15 2.00 4.70 2.00 85.25sda 3.06 41.84 444.90 54.08 14204.08 2048.98 7102.04 1024.49 32.57 2.10 4.21 1.85 92.24 磁盘的平均相应时间 &lt; 5ms ,磁盘使用率&gt;80。磁盘相应正常，但是比较繁忙。","categories":[],"tags":[{"name":"iostat","slug":"iostat","permalink":"http://blog.shicc.top/tags/iostat/"},{"name":"性能分析","slug":"性能分析","permalink":"http://blog.shicc.top/tags/性能分析/"}]},{"title":"liunx TCP/IP 优化","slug":"liunx-socket-setting","date":"2017-10-10T01:22:05.000Z","updated":"2018-12-03T10:19:55.672Z","comments":true,"path":"liunx-socket-setting.html","link":"","permalink":"http://blog.shicc.top/liunx-socket-setting.html","excerpt":"","text":"使用liunx进行压力测试时出现很多异常，都是java.net.NoRouteToHostException: Cannot assign requested address. 错误原因由于liunx 分配的客户端连接端口用尽，无法建立socket连接所致，虽然socket正常关闭，但是端口不是立即释放，而是处于 TIME_WAIT 状态，默认等待60s后释放。查看liunx支持的客户端连接端口范围，也就是 28232 个端口。12cat /proc/sys/net/ipv4/ip_local_port_range32768 - 61000 解决方法 调低端口释放后的等待时间，默认为60s,修改为15~30s。echo 30 &gt; /proc/sys/net/ipv4/tcp_fin_timeout 修改 tcp/ip 协议配置，通过配置 /proc/sys/net/ipv4/tcp_tw_reuse,默认为0，修改为1，释放TIME_WAIT端口给新连接使用。echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse 修改 ctp/ip 协议配置，快速回收socket资源，默认为0.修改为1。echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_recycle 参考网址木木de果冻儿的博客","categories":[],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://blog.shicc.top/tags/TCP-IP/"},{"name":"socket","slug":"socket","permalink":"http://blog.shicc.top/tags/socket/"},{"name":"liunx","slug":"liunx","permalink":"http://blog.shicc.top/tags/liunx/"}]},{"title":"Nginx中文路径404","slug":"nginx-404","date":"2017-10-10T01:22:05.000Z","updated":"2018-12-03T10:19:55.673Z","comments":true,"path":"nginx-404.html","link":"","permalink":"http://blog.shicc.top/nginx-404.html","excerpt":"","text":"Nginx 中文路径404 工具 SecureFXPortable 文件上传SecureCRTPortable shell 命令centos 操作系统 造成原因使用 SecureFXPortable 上传的中文文件夹在SecureCRTPortable中查看是乱码，导致nginx 无法匹配到相应的目录造成404。 处理方式 确保操作系统可以输入中文，并在 SecureCRTPortable中可以正确显示。 将 SecureFXPortable 和 SecureCRTPortable中的编码格式全部设置为utf-8。 在 SecureCRTPortable 安装的文件夹中进入 Data\\Settings\\Config\\Sessions 找到 相对应的 xx.xx.xx.xx.ini 文件，在文件中找到D:&quot;Filenames Always Use UTF8&quot; 将他的值修改为00000001","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.shicc.top/tags/Nginx/"},{"name":"中文url 404","slug":"中文url-404","permalink":"http://blog.shicc.top/tags/中文url-404/"},{"name":"SecureFXPortable 创建中文乱码","slug":"SecureFXPortable-创建中文乱码","permalink":"http://blog.shicc.top/tags/SecureFXPortable-创建中文乱码/"}]},{"title":"参数配置","slug":"zuul-config","date":"2017-10-09T11:03:49.000Z","updated":"2018-12-03T10:19:55.677Z","comments":true,"path":"zuul-config.html","link":"","permalink":"http://blog.shicc.top/zuul-config.html","excerpt":"","text":"配置参数说明1. id2. path 说明 匹配拦截url 3. serviceId 说明 需要配置 eureka , serviceId 为已注册的某一服务name。 4. url 说明 可以不需要配置 eureka , 直接重定向或者跳转到指定的 url 中，前缀的处理方式参考 stripPrefix 。 5. stripPrefix path 匹配是否保留path拦截部分，默认为true。true 不保留，false 保留。 12345678910zuul: ignoredServices: &apos;*&apos; host: connect-timeout-millis: 20000 socket-timeout-millis: 20000 routes: cache-service: path: /cache/** serviceId: data-cache-service stripPrefix: false 说明stripPrefix 为true，请求url http://localhost:8000/cache/index ,会实际跳转到微服务data-cache-service 中的 url为/index 的方法中。stripPrefix 为false，请求url http://localhost:8000/cache/index ,会实际跳转到微服务data-cache-service 中的 url为/cache/index 的方法中。 6. retryable7. sensitiveHeaders8. customSensitiveHeaders","categories":[],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.shicc.top/tags/Spring-Cloud/"},{"name":"Zuul","slug":"Zuul","permalink":"http://blog.shicc.top/tags/Zuul/"},{"name":"网关","slug":"网关","permalink":"http://blog.shicc.top/tags/网关/"}]},{"title":"限流方式","slug":"单机限流","date":"2017-10-09T11:03:49.000Z","updated":"2018-12-03T10:19:55.678Z","comments":true,"path":"单机限流.html","link":"","permalink":"http://blog.shicc.top/单机限流.html","excerpt":"","text":"限流的常用处理手段有：计数器、滑动窗口、漏桶、令牌。 限流神器Guava RateLimiterGuava RateLimiter 基于令牌桶算法，我们只需要告诉RateLimiter系统限制的QPS是读书，那么RateLimiter将以这个速度往桶里面放令牌，然后请求的时候，通过 tryAcquire() 方法向RateLimiter获取许可（令牌）。","categories":[],"tags":[{"name":"限流","slug":"限流","permalink":"http://blog.shicc.top/tags/限流/"}]},{"title":"开发过程中需要注意的安全问题","slug":"dev-security","date":"2017-09-30T03:22:34.000Z","updated":"2018-12-03T10:19:55.670Z","comments":true,"path":"dev-security.html","link":"","permalink":"http://blog.shicc.top/dev-security.html","excerpt":"","text":"开发过程中常见的安全问题必要系统参数需要加密java 开发，一般都使用spring，比如jdbc等系统参数参数我们通常会抽出一个jdbc.properites,大部分情况 jdbc.properties 中的数据都是明文展示的。这样假如我们的服务器被攻破那么数据库相关数据也基本可被攻击者完全查看到。 解决方法 对jdbc.properties中的必要数据做加密，不要在jdbc.properties显示重要的明文信息。 在 spring.xml 中需要引入jdbc.properties 并对相关信息进行解密。这样就无法通过&lt;context:property-placeholder location=&quot;classpath*:conf/*.properties&quot; ignore-unresolvable=&quot;true&quot;/&gt;通过这种方式来引入相关配置文件。而需要通过配置bean,并在bean对相关数据进行解密。123456789101112131415161718192021spring.xml&lt;bean class=&quot;com.adups.dbencrypt.EncryptPropertyPlaceholderConfigure&quot; p:locations=&quot;classpath*:conf/*.properties&quot; p:ignoreUnresolvablePlaceholders=&quot;true&quot;&gt;&lt;/bean&gt;EncryptPropertyPlaceholderConfigure.javapublic class EncryptPropertyPlaceholderConfigure extends PropertyPlaceholderConfigurer &#123; private String[] encryptPropNames = &#123;&quot;jdbc_url&quot;, &quot;jdbc_username&quot;,&quot;jdbc_password&quot;&#125;; protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, Properties props) throws BeansException &#123; try &#123; for (String prop : encryptPropNames) &#123; String url = props.getProperty(prop); if (url != null) &#123; props.setProperty(prop, DbEncryptUtils.getDecryptString(url)); &#125; &#125; super.processProperties(beanFactoryToProcess, props); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 文件上传限制文件上传必须对文件格式做限制，防止用户上传脚本木马。针对文件上传后展示最好使用nginx，针对tomcat不能让用户上传jsp文件。假如用户上传jsp文件，并调取上传的这个jsp，如果这个jsp经过tomcat解析，那么用户就可以通过上传jsp脚本木马获取到部署代码，并获得服务器。 java 执行shell 需要对特殊字符做过滤如果在java 程序中需要调取liunx shell 命令，那么在执行命令之前对用户传入的参数中的特殊字符（” ‘ | ）等做限制和替换。 XSS漏洞java web 一般使用 filter （XSSRequestWrapper）对请求参数进行参数格式化，过滤可能存在xss漏洞的参数。但是这个方法对 form 表单类型为multipart/form-data是没有效果的。所以针对form为multipart/form-data时，需要单独进行XSS处理。 获取IP我们从网上找java获取ip的代码，会发现很多代码都是从 request 的头中解析ip。但是这种方式很不安全，用户可以手动设置这些值导致ip获取不准确。使用request.getRemoteAddr();获取实际IP。 服务器权限针对一个服务器可能需要部署很多应用比如tomcat mysql nginx 等。针对不同的应用我们最好配置不同的用户，并严重控制每种用户的权限。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://blog.shicc.top/tags/java/"},{"name":"安全","slug":"安全","permalink":"http://blog.shicc.top/tags/安全/"},{"name":"spring 对参数加密","slug":"spring-对参数加密","permalink":"http://blog.shicc.top/tags/spring-对参数加密/"}]},{"title":"nginx配置location总结及rewrite规则写法","slug":"nginx-config","date":"2017-09-10T01:22:05.000Z","updated":"2018-12-03T10:19:55.673Z","comments":true,"path":"nginx-config.html","link":"","permalink":"http://blog.shicc.top/nginx-config.html","excerpt":"","text":"location正则写法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051location = / &#123; # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ] &#125;location / &#123; # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] &#125;location /documents/ &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ] &#125;location ~ /documents/Abc &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ] &#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ] &#125;location ~* \\.(gif|jpg|jpeg)$ &#123; # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ] &#125;location /images/ &#123; # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ] &#125;location /images/abc &#123; # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ] &#125;location ~ /images/abc/ &#123; # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ] &#125;location ~* /js/.*/\\.js 以 = 开头标识精确匹配 如 A 中只匹配根目录结尾的请求，后面不能带任何字符串 ^~ 开头表示 uri 以某个常规字符串开头，不是正则匹配。满足条件不需继续往下匹配 ~ 开头表示区分大小写的正则匹配，满足条件还需继续往下匹配 ~* 开头表示不区分大小写的正则匹配，满足条件还需继续往下匹配 / 通用匹配，如果没有其他匹配，任何请求都会匹配到 顺序 &lt;&gt; 优先级 (location=) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~， ~* 正则顺序) &gt; (location 部分起始路径) &gt; (/) 上面的匹配结果按照上面的location写法，以下的匹配示例成立： / -&gt; config A精确完全匹配，即使/index.html也匹配不了 /downloads/download.html -&gt; config B匹配B以后，往下没有任何匹配，采用B /images/1.gif -&gt; configuration D匹配到F，往下匹配到D，停止往下 /images/abc/def -&gt; config D最长匹配到G，往下匹配D，停止往下你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序 /documents/document.html -&gt; config C匹配到C，往下没有任何匹配，采用C /documents/1.jpg -&gt; configuration E匹配到C，往下正则匹配到E /documents/Abc.jpg -&gt; config CC最长匹配到C，往下正则顺序匹配到CC，不会往下到E 实际使用建议123456789101112131415161718192021所以实际使用中，个人觉得至少有三个匹配规则定义，如下：#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。#这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125;# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;#第三个规则就是通用规则，用来转发动态请求到后端应用服务器#非静态文件请求就默认是动态请求，自己根据实际把握#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/&#125; Rewrite规则rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag]; 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。 表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是： 执行server块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。 flag标志位 last : 相当于Apache的[L]标记，表示完成rewrite break : 停止执行当前虚拟主机的后续rewrite指令集 redirect : 返回302临时重定向，地址栏会显示跳转后的地址 permanent : 返回301永久重定向，地址栏会显示跳转后的地址 因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： last一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能组织继续执行后面的rewrite指令 if指令与全局变量if判断指令语法为if(condition){...}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配 -f和!-f用来判断是否存在文件-d和!-d用来判断是否存在目录-e和!-e用来判断是否存在文件或目录-x和!-x用来判断文件是否可执行 例如：12345678910111213141516171819202122232425262728293031if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; //如果UA包含&quot;MSIE&quot;，rewrite请求到/msid/目录下if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1; &#125; //如果cookie匹配正则，设置变量$id等于正则引用部分if ($request_method = POST) &#123; return 405;&#125; //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302if ($slow) &#123; limit_rate 10k;&#125; //限速，$slow可以通过 set 指令设置if (!-f $request_filename)&#123; break; proxy_pass http://127.0.0.1; &#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查if ($args ~ post=140)&#123; rewrite ^ http://example.com/ permanent;&#125; //如果query string中包含&quot;post=140&quot;，永久重定向到example.comlocation ~* \\.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) &#123; return 404; &#125; //防盗链&#125; 全局变量下面是可以用作if判断的全局变量 $args ： #这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 $document_uri ： 与$uri相同。 例：http://localhost:88/test1/test2/test.php$host：localhost$server_port：88$request_uri：http://localhost:88/test1/test2/test.php$document_uri：/test1/test2/test.php$document_root：/var/www/html$request_filename：/var/www/html/test1/test2/test.php 常用正则 . ： 匹配除换行符以外的任意字符 ? ： 重复0次或1次 + ： 重复1次或更多次 * ： 重复0次或更多次 \\d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 {n} ： 重复n次 {n,} ： 重复n次或更多次 [c] ： 匹配单个字符c [a-z] ： 匹配a-z小写字母的任意一个 小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。 rewrite实例12345678910111213141516171819202122232425262728293031http &#123; # 定义image日志格式 log_format imagelog &apos;[$time_local] &apos; $image_file &apos; &apos; $image_type &apos; &apos; $body_bytes_sent &apos; &apos; $status; # 开启重写日志 rewrite_log on; server &#123; root /home/www; location / &#123; # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免&#123;&#125; rewrite &apos;^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\\.(png|jpg|gif)$&apos; /data?file=$3.$4; # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行 set $image_file $3; set $image_type $4; &#125; location /data &#123; # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里 try_files /$arg_file /image404.html; &#125; location = /image404.html &#123; # 图片不存在返回特定的信息 return 404 &quot;image not found\\n&quot;; &#125;&#125; 对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。 例2：1rewrite ^/images/(.*)_(\\d+)x(\\d+)\\.(png|jpg|gif)$ /resizer/$1.$4?width=$2&amp;height=$3? last; 对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.shicc.top/tags/nginx/"}]},{"title":"Spring Boot 上传文件","slug":"spring-boot-file-upload","date":"2017-09-05T03:39:33.000Z","updated":"2018-12-03T10:19:55.675Z","comments":true,"path":"spring-boot-file-upload.html","link":"","permalink":"http://blog.shicc.top/spring-boot-file-upload.html","excerpt":"","text":"Spring Boot 上传文件依赖jar pom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; java12345678910111213141516171819202122232425262728293031323334353637383940414243444546@RestController@RequestMappingpublic class UploadController &#123; @RequestMapping(value = &quot;/uploadDelta.do&quot;) @ResponseBody public Map&lt;String, Object&gt; updateDelta(MultipartFile file) &#123; Map&lt;String, Object&gt; result = new HashMap&lt;String, Object&gt;(); String rootFilePath = uploadpath; //文件最后保存的目录 String path_save = &quot;/&quot; + paramer.getProjectId() + &quot;/&quot; + deltaEntity.getId() + &quot;/&quot;;/**文件保存路径（没有文件名称）**/ String saveFilePath = rootFilePath + path_save; File allPathFile = new File(saveFilePath); if (!allPathFile.exists()) &#123; allPathFile.mkdirs(); logger.info(&quot;创建文件夹，路径：&quot; + allPathFile); &#125; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); String fileName = paramer.getFile().getOriginalFilename(); //获取文件名 String[] fileNameSplit = fileName.split(&quot;\\\\.&quot;);//获取文件拓展名 String compress = fileNameSplit[fileNameSplit.length - 1]; String randomFilename = UUID.randomUUID().toString() + &quot;.&quot; + compress; File destFile = new File(saveFilePath + randomFilename);//随机生成的文件名 logger.info(&quot;文件保存路径：&quot; + saveFilePath + randomFilename); try &#123;//文件写入硬盘 paramer.getFile().transferTo(new File(saveFilePath + randomFilename)); &#125; catch (Exception e) &#123; e.printStackTrace(); logger.error(&quot;文件保存到硬盘失败&quot;); result.put(&quot;status&quot;, ResultParams.PROJECT_FAIL_STATUS); result.put(&quot;msg&quot;, &quot;文件上传失败&quot;); return result; &#125; return null; &#125;&#125; 大文件上传异常 spring boot 限制一次表单提交总共文件的最大大小为10MB,每一个文件的大小为1MB.1234MultipartPropertiesprivate String maxFileSize = &quot;1Mb&quot;;private String maxRequestSize = &quot;10Mb&quot;; 解决方法 直接通过配置文件解决 application.properties 1234spring.http.multipart.max-request-size=1024MB # 大小设置为1Gspring.http.multipart.max-file-size=1024MB# 大小设置为1G 通过代码层级修改文件上传大小限制 12345678910111213import org.springframework.web.multipart.MultipartResolver;import org.springframework.web.multipart.commons.CommonsMultipartResolver;@Bean(name = &quot;multipartResolver&quot;)public MultipartResolver multipartResolver() &#123; CommonsMultipartResolver resolver = new CommonsMultipartResolver(); resolver.setDefaultEncoding(&quot;UTF-8&quot;); resolver.setResolveLazily(true);//resolveLazily属性启用是为了推迟文件解析，以在在UploadAction中捕获文件大小异常 resolver.setMaxInMemorySize(40960); resolver.setMaxUploadSize(500 * 1024 * 1024);//上传文件大小 50M 50*1024*1024 return resolver;&#125; 在spring boot 1.5.4版本中可以直接通过 @Bean(&quot;multipartResolver&quot;) 进行注入。 注意点","categories":[],"tags":[{"name":"spring Boot","slug":"spring-Boot","permalink":"http://blog.shicc.top/tags/spring-Boot/"},{"name":"文件上传","slug":"文件上传","permalink":"http://blog.shicc.top/tags/文件上传/"}]},{"title":"hash","slug":"hash","date":"2017-06-13T10:48:52.000Z","updated":"2018-12-03T10:19:55.670Z","comments":true,"path":"hash.html","link":"","permalink":"http://blog.shicc.top/hash.html","excerpt":"","text":"Hash摘要数据结构基本分为 结构体（或对象） 数组 链表 哈希函数Hash也叫散列，hash操作其本质上就是建给一个数据映射成另一个数据，通常情况下原数据的长度比hash后的数据容量大。这种映射关系我们称为哈希函数。通常 哈希函数的输入要远远多于哈希值所表示的总数，就有可能两个不同的输入对应同一个哈希值。通常把具有不同关键码而具有相同哈希值的记录称为“同义词”。 哈希表哈希表是一种数据结构，实现key-value的快速存取。 HasshCode 相等的对象必须要有相同的哈希码。 不相等的对象可能会存在相同的哈希码。 有同一个哈希值的对象不一定相等。HashCode 不可信，因此不要将 HashCode 作为key。使用基于哈希的算法，比如 SHA1 。来降低hashcode的冲突。 HashTableHashMap线程不安全的原因因为在自动调整大小的机制下，如果线程试着去添加或者获取一个对象，Map可能会使用旧的索引值，这样就不会找到Entry对象所在的新桶。 保证线程安全的HashMap实现：ConcurrentHashMap。对于ConcurrentMap来说，只有桶是同步的，这样如果多个线程不使用同一个桶或者调整内部数组的大小，它们可以同时调用get(),remove(),或者put()方法。","categories":[],"tags":[]},{"title":"Spring Cloud 乱码","slug":"spring-cloud-coding","date":"2017-05-21T03:52:57.000Z","updated":"2018-12-03T10:19:55.676Z","comments":true,"path":"spring-cloud-coding.html","link":"","permalink":"http://blog.shicc.top/spring-cloud-coding.html","excerpt":"","text":"Spring Boot RestTemplate 中文乱码解决方法1234567891011121314@Beanpublic RestTemplate restTemplate() &#123; RestTemplate restTemplate = new RestTemplate(); List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters = new ArrayList&lt;HttpMessageConverter&lt;?&gt;&gt;(); messageConverters.addAll(restTemplate.getMessageConverters()); for(HttpMessageConverter&lt;?&gt; converter :messageConverters) &#123; if(converter instanceof StringHttpMessageConverter) &#123; converter = new StringHttpMessageConverter(Charset.forName(&quot;UTF-8&quot;)); break; &#125; &#125; restTemplate.setMessageConverters(messageConverters); return restTemplate;&#125; Spring Cloud Feign HttpClient 中文乱码Spring Cloud Feign HttpClient 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.6.0&lt;/version&gt; &lt;/dependency&gt; Spring Cloud Feign HttpClient 传递中文乱码 推荐使用 ok-http12345678&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;/dependency&gt;","categories":[],"tags":[{"name":"SpringCloud 乱码","slug":"SpringCloud-乱码","permalink":"http://blog.shicc.top/tags/SpringCloud-乱码/"},{"name":"RestTemplate","slug":"RestTemplate","permalink":"http://blog.shicc.top/tags/RestTemplate/"},{"name":"Feign","slug":"Feign","permalink":"http://blog.shicc.top/tags/Feign/"},{"name":"HttpClient","slug":"HttpClient","permalink":"http://blog.shicc.top/tags/HttpClient/"}]},{"title":"搭建直播流服务器","slug":"living-service","date":"2017-05-19T10:30:21.000Z","updated":"2018-12-03T10:19:55.673Z","comments":true,"path":"living-service.html","link":"","permalink":"http://blog.shicc.top/living-service.html","excerpt":"","text":"搭建直播流服务器技术 Nginx nginx-rtmp-module-1.1.11 （nginx 插件） 步骤 下载nginx 和 nginx-rtmp-module 源文件 解压 nginx 和 nginx-rtmp-module ./configure –add-module=/home/shichangcheng/live/nginx-rtmp-module-1.1.11（将nginx第三方模块加入nginx） make ； make install； 配置nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # hls living location /stat &#123; rtmp_stat all; rtmp_stat_stylesheet stat.xsl; &#125; location /stat.xsl &#123; root /usr/local/nginx/html/nginx-rtmp-module/; &#125; location /control &#123; rtmp_control all; &#125; location /hls &#123; types&#123; application/vnd.apple.mpegurl m3u8; video/mp2t ts; &#125; root /home/shichangcheng/live/my-app; &#125; &#125;&#125;rtmp &#123; server &#123; listen 1935; application hls &#123; live on; hls on; hls_path /home/shichangcheng/live/my-app/hls; hls_fragment 5s; &#125; application live&#123; live on; max_connections 1024; allow play all; record_path /home/shichangcheng/live/my-app/live; recorder audio &#123; record audio; record_suffix -%d-%b-%y-%T.flv; &#125; recorder chunked &#123; record all; #record_max_size 5120K; record_interval 15s; record_path /home/shichangcheng/live/my-app/live/chunked; &#125; &#125; &#125;&#125; 遇到的问题 liunx 的权限 nginx user 修改为root rtmp 中 record_path 保存客户端采集视频信息推动到服务器的地址，需要注意该文件的读写权限。 防火墙 iptables -A INPUT -m state –state NEW -m tcp -p tcp –dport 1935 -j ACCEPT 推流地址rtmp://123.206.231.130/hls/（movie）（movie）为表示生成流文件的名字 播放地址rtmp地址：rtmp://123.206.231.130/hls/（movie）hvl 地址：http://123.206.231.138/hls/movie.m3u8 直播协议 rtmp ：rtmp 延时较低，需要使用flash，或者解码器才能播放。 hlv ：hlv 延时较高，自己测未进过cdn一般优化，延时5。移动端网页播放使用HLV协议。 客户端 直播工具可以使用金山云的DEMO 播放器 H5 只能使用 hlv 地址 金山云提供的播放SDK PC客户端 VLC Media Player","categories":[],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.shicc.top/tags/Nginx/"},{"name":"直播","slug":"直播","permalink":"http://blog.shicc.top/tags/直播/"},{"name":"nginx-rtmp-module","slug":"nginx-rtmp-module","permalink":"http://blog.shicc.top/tags/nginx-rtmp-module/"}]}]}